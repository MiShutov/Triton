{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea71bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import marlin\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "\n",
    "DEV = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5c06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_quant4(m, n, groupsize=-1):\n",
    "\tmaxq = 2 ** 4 - 1\n",
    "\tw = torch.randn((m, n), dtype=torch.half, device=DEV)\n",
    "\tif groupsize != -1:\n",
    "\t\tw = w.reshape((-1, groupsize, n))\n",
    "\t\tw = w.permute(1, 0, 2)\n",
    "\t\tw = w.reshape((groupsize, -1))\n",
    "\ts = torch.max(torch.abs(w), 0, keepdim=True)[0]\n",
    "\ts *= 2 / maxq\n",
    "\tw = torch.round(w / s).int()\n",
    "\tw += (maxq + 1) // 2\n",
    "\tw = torch.clamp(w, 0, maxq)\n",
    "\tref = (w - (maxq + 1) // 2).half() * s\n",
    "\tif groupsize != -1:\n",
    "\t\tdef reshape(w):\n",
    "\t\t\tw = w.reshape((groupsize, -1, n))\n",
    "\t\t\tw = w.permute(1, 0, 2)\n",
    "\t\t\tw = w.reshape((m, n)).contiguous()\n",
    "\t\t\treturn w\n",
    "\t\tref = reshape(ref)\n",
    "\t\tw = reshape(w)\n",
    "\ts = s.reshape((-1, n)).contiguous()\n",
    "\tlinear = nn.Linear(m, n)\n",
    "\tlinear.weight.data = ref.t()\n",
    "\t# Workaround to test some special cases that are forbidden by the API\n",
    "\tlayer = marlin.Layer(256, 256, groupsize=groupsize)\n",
    "\tif groupsize == -1:\n",
    "\t\tgroupsize = m\n",
    "\tlayer.k = m\n",
    "\tlayer.n = n\n",
    "\tlayer.groupsize = groupsize\n",
    "\tlayer.B = torch.empty((m // 16, n * 16 // 8), dtype=torch.int, device=DEV)\n",
    "\tlayer.s = torch.empty((m // groupsize, n), dtype=torch.half, device=DEV)\n",
    "\tlayer.pack(linear, s.t())\n",
    "\tq = layer.B\n",
    "\ts = layer.s\n",
    "\treturn ref, q, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291a0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_problem(m, n, k, thread_k, thread_n, groupsize=-1):\n",
    "    print('% 5d % 6d % 6d % 4d % 4d % 4d' % (m, n, k, thread_k, thread_n, groupsize))\n",
    "    A = torch.randn((m, k), dtype=torch.half, device=DEV)\n",
    "    B_ref, B, s = gen_quant4(k, n, groupsize=groupsize)\n",
    "    C = torch.zeros((m, n), dtype=torch.half, device=DEV)\n",
    "    C_ref = torch.matmul(A, B_ref)\n",
    "    workspace = torch.zeros(n // 128 * 16, device=DEV)\n",
    "    marlin.mul(A, B, C, s, workspace, thread_k, thread_n, -1)\n",
    "    torch.cuda.synchronize()\n",
    "    print(torch.mean(torch.abs(C - C_ref)) / torch.mean(torch.abs(C_ref)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05afab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8   4096   4096  128  128  128\n",
      "tensor(0.0001, device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "m = 8\n",
    "groupsize = 128\n",
    "thread_shape = (128, 128) # (64, 256)\n",
    "n, k = (4096, 4096) #, (256, 1024), (256 * 128, 1024)\n",
    "\n",
    "run_problem(m, n, k, *thread_shape, groupsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9cee6da",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d423d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v] [-q] [--locals] [--durations N] [-f]\n",
      "                             [-c] [-b] [-k TESTNAMEPATTERNS]\n",
      "                             [tests ...]\n",
      "ipykernel_launcher.py: error: argument -f/--failfast: ignored explicit argument '/run/user/1000/jupyter/runtime/kernel-v3d8cdae7c080261ab3ac3f950288b7a62579af448.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msst/Utils/miniconda3/envs/triton_env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class Test(unittest.TestCase):\n",
    "\n",
    "\tdef run_problem(self, m, n, k, thread_k, thread_n, groupsize=-1):\n",
    "\t\tprint('% 5d % 6d % 6d % 4d % 4d % 4d' % (m, n, k, thread_k, thread_n, groupsize))\n",
    "\t\tA = torch.randn((m, k), dtype=torch.half, device=DEV)\n",
    "\t\tB_ref, B, s = gen_quant4(k, n, groupsize=groupsize)\n",
    "\t\tC = torch.zeros((m, n), dtype=torch.half, device=DEV)\n",
    "\t\tC_ref = torch.matmul(A, B_ref)\n",
    "\t\tworkspace = torch.zeros(n // 128 * 16, device=DEV)\n",
    "\t\tmarlin.mul(A, B, C, s, workspace, thread_k, thread_n, -1)\n",
    "\t\ttorch.cuda.synchronize()\n",
    "\t\tself.assertLess(torch.mean(torch.abs(C - C_ref)) / torch.mean(torch.abs(C_ref)), 0.001)\n",
    "\n",
    "\tdef test_tiles(self):\n",
    "\t\tprint()\n",
    "\t\tfor m in [1, 2, 3, 4, 8, 12, 16, 24, 32, 48, 64, 118, 128, 152, 768, 1024]:\n",
    "\t\t\tfor thread_k, thread_n in [(64, 256), (128, 128)]:\n",
    "\t\t\t\tif m > 16 and thread_k == 128:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tself.run_problem(m, 2 * 256, 1024, thread_k, thread_n)\n",
    "\n",
    "\tdef test_k_stages_divisibility(self):\n",
    "\t\tprint()\n",
    "\t\tfor k in [3 * 64 + 64 * 4 * 2 + 64 * i for i in range(1, 4)]:\n",
    "\t\t\tself.run_problem(16, 2 * 256, k, 64, 256)\n",
    "\n",
    "\tdef test_very_few_stages(self):\n",
    "\t\tprint()\n",
    "\t\tfor k in [64, 128, 192]:\n",
    "\t\t\tself.run_problem(16, 2 * 256, k, 64, 256)\n",
    "\n",
    "\tdef test_llama_shapes(self):\n",
    "\t\tprint()\n",
    "\t\treturn\n",
    "\t\tMODELS = {\n",
    "\t\t\t' 7B': [\n",
    "\t\t\t\t(4096, 3 * 4096),\n",
    "\t\t\t\t(4096, 4096),\n",
    "\t\t\t\t(4096, 2 * 10752),\n",
    "\t\t\t\t(10752, 4096)\n",
    "\t\t\t],\n",
    "\t\t\t'13B': [\n",
    "\t\t\t\t(5120, 3 * 5120),\n",
    "\t\t\t\t(5120, 5120),\n",
    "\t\t\t\t(5120, 2 * 13568),\n",
    "\t\t\t\t(13568, 5120)\n",
    "\t\t\t],\n",
    "\t\t\t'33B': [\n",
    "\t\t\t\t(6656, 3 * 6656),\n",
    "\t\t\t\t(6656, 6656),\n",
    "\t\t\t\t(6656, 2 * 17664),\n",
    "\t\t\t\t(17664, 6656)\n",
    "\t\t\t],\n",
    "\t\t\t'70B': [\n",
    "\t\t\t\t(8192, 3 * 8192),\n",
    "\t\t\t\t(8192, 8192),\n",
    "\t\t\t\t(8192, 2 * 21760),\n",
    "\t\t\t\t(21760, 8192)\n",
    "\t\t\t]\n",
    "\t\t}\n",
    "\t\tfor _, layers in MODELS.items():\n",
    "\t\t\tfor layer in layers:\n",
    "\t\t\t\tfor thread_k, thread_n in [(128, 128)]:\n",
    "\t\t\t\t\tfor batch in [1, 16]:\n",
    "\t\t\t\t\t\tself.run_problem(batch, layer[1], layer[0], thread_k, thread_n)\n",
    "\n",
    "\tdef test_errors(self):\n",
    "\t\tprint()\n",
    "\t\tm, n, k = 16, 256, 64\n",
    "\t\tA = torch.randn((m, k), dtype=torch.half, device=DEV)\n",
    "\t\tB_ref, B, s = gen_quant4(k, n)\n",
    "\t\tC = torch.zeros((m, n), dtype=torch.half, device=DEV)\n",
    "\t\tworkspace = torch.zeros(n // 128, device=DEV)\n",
    "\t\terr = False\n",
    "\t\ttry:\n",
    "\t\t\tmarlin.mul(A, B, C, s, workspace, 128, 128, -1)\n",
    "\t\texcept:\n",
    "\t\t\terr = True \n",
    "\t\tself.assertTrue(err)\n",
    "\t\terr = False\n",
    "\t\ttry:\n",
    "\t\t\tmarlin.mul(A, B, C, s, workspace, 256, 256, -1)\n",
    "\t\texcept:\n",
    "\t\t\terr = True \n",
    "\t\tself.assertTrue(err)\n",
    "\t\ts = torch.zeros((2, n), dtype=torch.half, device=DEV)\n",
    "\t\terr = False\n",
    "\t\ttry:\n",
    "\t\t\tmarlin.mul(A, B, C, s, workspace, 256, 256, -1)\n",
    "\t\texcept:\n",
    "\t\t\terr = True \n",
    "\t\tself.assertTrue(err)\n",
    "\n",
    "\tdef test_groups(self):\n",
    "\t\tprint()\n",
    "\t\tfor m in [16]:\n",
    "\t\t\tfor groupsize in [128]:\n",
    "\t\t\t\tfor n, k in [(256, 512), (256, 1024), (256 * 128, 1024)]:\n",
    "\t\t\t\t\tfor thread_shape in [(128, 128), (64, 256)]:\n",
    "\t\t\t\t\t\tself.run_problem(m, n, k, *thread_shape, groupsize)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "unittest.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
