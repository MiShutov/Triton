{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbe9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "# os.environ['TRITON_INTERPRET'] = '1'\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import math\n",
    "\n",
    "DEVICE = triton.runtime.driver.active.get_active_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2b2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_cuda_autotune_config():\n",
    "    configs = []\n",
    "    for num_stages in [2,4]:\n",
    "        for num_warps in [2,4,8]:\n",
    "            for BLOCK_SIZE_M in [32, 64, 128]:#, 128]:\n",
    "                for BLOCK_SIZE_N in [32, 64, 128]:#[64, 128]:\n",
    "                    for BLOCK_SIZE_K in [16, 32]:#[16, 32]:\n",
    "                        configs.append(\n",
    "                            triton.Config(\n",
    "                                {\n",
    "                                    \"GROUP_SIZE_M\" : 8,\n",
    "                                    \"BLOCK_SIZE_M\" : BLOCK_SIZE_M,\n",
    "                                    \"BLOCK_SIZE_N\" : BLOCK_SIZE_N,\n",
    "                                    \"BLOCK_SIZE_K\" : BLOCK_SIZE_K,\n",
    "                                }, \n",
    "                                num_stages=num_stages, \n",
    "                                num_warps=num_warps\n",
    "                            ),\n",
    "                        )                        \n",
    "    return configs\n",
    "\n",
    "    # return [triton.Config(\n",
    "    #                             {\n",
    "    #                                 \"GROUP_SIZE_M\" : 8,\n",
    "    #                                 \"BLOCK_SIZE_M\" : 16,\n",
    "    #                                 \"BLOCK_SIZE_N\" : 16,\n",
    "    #                                 \"BLOCK_SIZE_K\" : 16,\n",
    "    #                             },\n",
    "    #                             num_stages=2, \n",
    "    #                             num_warps=4\n",
    "    #                         )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2683f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"GROUP_SIZE_M\" : 8,\n",
    "                \"BLOCK_SIZE_M\" : 64,\n",
    "                \"BLOCK_SIZE_N\" : 128,\n",
    "                \"BLOCK_SIZE_K\" : 16,\n",
    "            },\n",
    "            num_stages=2, \n",
    "            num_warps=4\n",
    "        )\n",
    "    ],\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_fp16(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N // 2) + tl.arange(0, BLOCK_SIZE_N // 2)) % (N // 2)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    # For bits unpack\n",
    "    shifter = tl.arange(0, 2) * 4\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "    accumulator_dtype = tl.float32 #tl.float16\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)        \n",
    "        b_bits = tl.load(b_ptrs) #, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        b = (b_bits[:, :, None] >> shifter[None, None, :]) & 0xF\n",
    "        b = tl.reshape(b, BLOCK_SIZE_K, BLOCK_SIZE_N) - 0x8\n",
    "        b = b.to(tl.float16)\n",
    "        \n",
    "        # We accumulate along the K dimension.\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "\n",
    "    c = accumulator.to(tl.float16)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_int4_fp16(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int8\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] * 2\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_fp16[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94af5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    # configs=_get_cuda_autotune_config(),\n",
    "    configs=[\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"GROUP_SIZE_M\" : 8,\n",
    "                \"BLOCK_SIZE_M\" : 128,\n",
    "                \"BLOCK_SIZE_N\" : 128,\n",
    "                \"BLOCK_SIZE_K\" : 16,\n",
    "            },\n",
    "            num_stages=4, \n",
    "            num_warps=4\n",
    "        )\n",
    "    ],\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_int4_fp16_scaled(\n",
    "        scales_ptr,\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N // 2) + tl.arange(0, BLOCK_SIZE_N // 2)) % (N // 2)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    scales_ptrs = scales_ptr + pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "\n",
    "    # For bits unpack\n",
    "    shifter = tl.arange(0, 2) * 4\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "    accumulator_dtype = tl.float32 #tl.float16\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)        \n",
    "        b_bits = tl.load(b_ptrs) #, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        b = (b_bits[:, :, None] >> shifter[None, None, :]) & 0xF\n",
    "        b = tl.reshape(b, BLOCK_SIZE_K, BLOCK_SIZE_N) - 0x8\n",
    "        \n",
    "        scales = tl.load(scales_ptrs)\n",
    "        b = b.to(tl.float16) * scales[None, :]\n",
    "\n",
    "        # We accumulate along the K dimension.\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "\n",
    "    c = accumulator.to(tl.float16)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_int4_fp16_scaled(a, b, scales):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int8\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] * 2\n",
    "    \n",
    "    assert list(scales.shape) == [N,]\n",
    "    assert scales.dtype == torch.float16\n",
    "    \n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_int4_fp16_scaled[grid](\n",
    "        scales,\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0d095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    # configs=_get_cuda_autotune_config(),\n",
    "    configs=[\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"GROUP_SIZE_M\" : 8,\n",
    "                \"BLOCK_SIZE_M\" : 64,\n",
    "                \"BLOCK_SIZE_N\" : 128,\n",
    "                \"BLOCK_SIZE_K\" : 16,\n",
    "            },\n",
    "            num_stages=2, \n",
    "            num_warps=4\n",
    "        )\n",
    "    ],\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_int2_fp16(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N // 4) + tl.arange(0, BLOCK_SIZE_N // 4)) % (N // 4)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    # For bits unpack\n",
    "    shifter = tl.arange(0, 4) * 2\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "    accumulator_dtype = tl.float32 #tl.float16\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)        \n",
    "        b_bits = tl.load(b_ptrs) #, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        b = (b_bits[:, :, None] >> shifter[None, None, :]) & 0x3\n",
    "        b = tl.reshape(b, BLOCK_SIZE_K, BLOCK_SIZE_N) - 0x2\n",
    "        b = b.to(tl.float16)\n",
    "        \n",
    "        # We accumulate along the K dimension.\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "\n",
    "    c = accumulator.to(tl.float16)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_int2_fp16(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int8\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] * 4\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_int2_fp16[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77e3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"GROUP_SIZE_M\" : 8,\n",
    "                \"BLOCK_SIZE_M\" : 64,\n",
    "                \"BLOCK_SIZE_N\" : 128,\n",
    "                \"BLOCK_SIZE_K\" : 16,\n",
    "            },\n",
    "            num_stages=4,\n",
    "            num_warps=4\n",
    "        )\n",
    "    ],\n",
    "    # configs=_get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_fp16_bigpack(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N // 8) + tl.arange(0, BLOCK_SIZE_N // 8)) % (N // 8)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    # For bits unpack\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "    accumulator_dtype = tl.float32 #tl.float16\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)        \n",
    "        b_bits = tl.load(b_ptrs) #, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        b = (b_bits[:, :, None] >> shifter[None, None, :]) & 0xF\n",
    "        b = tl.reshape(b, BLOCK_SIZE_K, BLOCK_SIZE_N) - 0x8\n",
    "        b = b.to(tl.float16)\n",
    "        \n",
    "        # We accumulate along the K dimension.\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "\n",
    "    c = accumulator.to(tl.float16)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_int4_fp16_bigpack(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] * 8\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_fp16_bigpack[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0b8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config(\n",
    "            {\n",
    "                \"GROUP_SIZE_M\" : 8,\n",
    "                \"BLOCK_SIZE_M\" : 64,\n",
    "                \"BLOCK_SIZE_N\" : 64,\n",
    "                \"BLOCK_SIZE_K\" : 16,\n",
    "            },\n",
    "            num_stages=2, \n",
    "            num_warps=4\n",
    "        )\n",
    "    ],\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_fp32(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "        # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`\n",
    "        # by to get the element one row down (A has M rows).\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N // 2) + tl.arange(0, BLOCK_SIZE_N // 2)) % (N // 2)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    # For bits unpack\n",
    "    shifter = tl.arange(0, 2) * 4\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)        \n",
    "        b_bits = tl.load(b_ptrs) #, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "\n",
    "        b = (b_bits[:, :, None] >> shifter[None, None, :]) & 0xF\n",
    "        b = tl.reshape(b, BLOCK_SIZE_K, BLOCK_SIZE_N) - 0x8\n",
    "        b = b.to(tl.float32)\n",
    "        \n",
    "        # We accumulate along the K dimension.\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "\n",
    "    c = accumulator # .to(tl.float16)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_int4_fp32(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float32\n",
    "    assert b.dtype == torch.int8\n",
    "\n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] * 2\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float32)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_fp32[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa8dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_int8_to_int4(bits):\n",
    "    v1 = (bits >> 4) & 0xF\n",
    "    v0 = bits & 0xF\n",
    "\n",
    "    w = torch.stack([v0, v1], dim=-1) - 0x8\n",
    "    return w.reshape(bits.shape[0], bits.shape[1] * 2)\n",
    "\n",
    "\n",
    "def decode_int8_to_int2(bits):\n",
    "    v3 = (bits >> 6) & 0x3\n",
    "    v2 = (bits >> 4) & 0x3\n",
    "    v1 = (bits >> 2) & 0x3\n",
    "    v0 = bits & 0x3\n",
    "\n",
    "    w = torch.stack([v0, v1, v2, v3], dim=-1) - 0x2\n",
    "    return w.reshape(bits.shape[0], bits.shape[1] * 4)\n",
    "\n",
    "\n",
    "def decode_int32_to_int4(bits):\n",
    "    v0 = bits & 0xF\n",
    "    v1 = (bits >> 4) & 0xF\n",
    "    v2 = (bits >> 8) & 0xF\n",
    "    v3 = (bits >> 12) & 0xF\n",
    "    v4 = (bits >> 16) & 0xF\n",
    "    v5 = (bits >> 20) & 0xF\n",
    "    v6 = (bits >> 24) & 0xF\n",
    "    v7 = (bits >> 28) & 0xF\n",
    "    \n",
    "    w = torch.stack([v0, v1, v2, v3, v4, v5, v6, v7], dim=-1) - 0x8\n",
    "    return w.reshape(bits.shape[0], bits.shape[1] * 8)\n",
    "\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "# M, N, K = 3 * (4096,)\n",
    "# M, N, K = 3 * (1024,)\n",
    "# M, N, K = 3 * (16,)\n",
    "\n",
    "# y = torch.randn(M, K, dtype=torch.float16, device=\"cuda\") / (M * K)\n",
    "# x_compressed = torch.randint(-128, 128, (K, N // 2), dtype=torch.int8, device=\"cuda\")\n",
    "# x_decompressed = decode_int8_to_int4(x_compressed)\n",
    "\n",
    "# o1 = torch.matmul(y, x_decompressed.to(torch.float16)\n",
    "#                   )\n",
    "# o2 = triton_matmul_int4_fp16(y, x_compressed)\n",
    "# print(matmul_kernel_fp16.best_config)\n",
    "# # assert torch.all(torch.isclose(o1, o2))\n",
    "\n",
    "# o3 = triton_matmul_int4_fp32(y.float(), x_compressed)\n",
    "# print(matmul_kernel_fp32.best_config)\n",
    "# # assert torch.all(torch.isclose(o1, o3))\n",
    "\n",
    "# x_compressed_32bit = torch.randint(-2**31, 2**31, (K, N // 8), dtype=torch.int32, device=\"cuda\")\n",
    "# x_decompressed = decode_int32_to_int4(x_compressed_32bit)\n",
    "\n",
    "# o3 = triton_matmul_int4_fp16_bigpack(y, x_compressed_32bit)\n",
    "# print(matmul_kernel_fp16_bigpack.best_config)\n",
    "\n",
    "# x_compressed = torch.randint(-128, 128, (K, N // 4), dtype=torch.int8, device=\"cuda\")\n",
    "# x_decompressed = decode_int8_to_int2(x_compressed)\n",
    "\n",
    "# o1 = torch.matmul(y, x_decompressed.to(torch.float16))\n",
    "# o2 = triton_matmul_int2_fp16(y, x_compressed)\n",
    "# print(matmul_kernel_int2_fp16.best_config)\n",
    "\n",
    "\n",
    "# x_compressed = torch.randint(-128, 128, (K, N // 2), dtype=torch.int8, device=\"cuda\")\n",
    "# scales = torch.abs(torch.randn(N, dtype=torch.float16, device=\"cuda\"))\n",
    "# o2 = triton_matmul_int4_fp16_scaled(y, x_compressed, scales)\n",
    "# print(matmul_kernel_int4_fp16_scaled.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90b8959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul-performance:\n",
      "        M       N       K  torch_fp32  int4_fp16_scaled\n",
      "0   256.0   256.0   256.0    0.606815          0.469266\n",
      "1   512.0   512.0   512.0    1.394383          1.438129\n",
      "2  1024.0  1024.0  1024.0    2.430160          2.405594\n",
      "3  2048.0  2048.0  2048.0    2.019728          2.351263\n",
      "4  4096.0  4096.0  4096.0    0.752401          2.234207\n",
      "5  8192.0  8192.0  8192.0    0.472481          2.215556\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BS = 1\n",
    "sizes = [256, 512, 1024, 2048, 4096, 8192]\n",
    "configs = []\n",
    "configs.append(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\", \"N\", \"K\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[(BS * size, size, size) for size in sizes],\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        # Don't compare to cublas for fp8 cases as torch.matmul doesn't support fp8 at the moment.\n",
    "        line_vals=[\n",
    "            \"torch_fp32\", \n",
    "            # \"torch_fp16\", \n",
    "            # \"triton_int2_fp16\",\n",
    "            # \"triton_int4_fp16\",\n",
    "            \"triton_int4_fp16_scaled\",\n",
    "            # \"triton_int4_fp16_bigpack\",\n",
    "            # \"triton_int4_fp32\",\n",
    "            ],  # Label name for the lines\n",
    "        line_names=[\n",
    "            \"torch_fp32\", \n",
    "            # \"torch_fp16\", \n",
    "            # \"int2_fp16\",\n",
    "            # \"int4_fp16\", \n",
    "            \"int4_fp16_scaled\", \n",
    "            # \"int4_fp16_bigpack\",\n",
    "            # \"int4_fp32\", \n",
    "            ],  # Line styles\n",
    "        #styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"TFLOPS\",  # Label name for the y-axis\n",
    "        xlabel=\"Matrix size\",\n",
    "        plot_name=\"matmul-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={},\n",
    "    ))\n",
    "\n",
    "\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, K, N, provider):\n",
    "    y_fp16 = torch.randn(M, K, dtype=torch.float16, device=\"cuda\").contiguous() / (M * K)\n",
    "    y_fp32 = torch.randn(M, K, dtype=torch.float32, device=\"cuda\").contiguous() / (M * K)\n",
    "\n",
    "    # x_compressed_int2 = torch.randint(-128, 128, (K, N // 4), dtype=torch.int8, device=\"cuda\").contiguous()\n",
    "    x_compressed_int4 = torch.randint(-128, 128, (K, N // 2), dtype=torch.int8, device=\"cuda\").contiguous()\n",
    "    # x_compressed_int4_bigpack = torch.randint(-2**31, 2**31, (K, N // 8), dtype=torch.int32, device=\"cuda\").contiguous()\n",
    "    # x_decompressed_fp16 = decode_int8_to_int4(x_compressed_int4).reshape(K, N).to(torch.float16).contiguous()\n",
    "    x_decompressed_fp32 = decode_int8_to_int4(x_compressed_int4).reshape(K, N).to(torch.float32).contiguous()\n",
    "    scales = torch.abs(torch.randn(N, dtype=torch.float16, device=\"cuda\"))\n",
    "\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == \"torch_fp32\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(y_fp32, x_decompressed_fp32), quantiles=quantiles)\n",
    "    if provider == \"torch_fp16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(y_fp16, x_decompressed_fp16), quantiles=quantiles)\n",
    "    if provider == \"triton_int2_fp16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_int2_fp16(y_fp16, x_compressed_int2), quantiles=quantiles)\n",
    "    if provider == \"triton_int4_fp16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_int4_fp16(y_fp16, x_compressed_int4), quantiles=quantiles)\n",
    "    if provider == \"triton_int4_fp16_scaled\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_int4_fp16_scaled(y_fp16, x_compressed_int4, scales), quantiles=quantiles)\n",
    "    if provider == \"triton_int4_fp16_bigpack\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_int4_fp16_bigpack(y_fp16, x_compressed_int4_bigpack), quantiles=quantiles)\n",
    "    # if provider == \"triton_int4_fp32\":\n",
    "    #     ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_int4_fp32(y_fp32, x_compressed), quantiles=quantiles)\n",
    "    perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n",
    "\n",
    "benchmark.run(show_plots=False, print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2f9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a455c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
