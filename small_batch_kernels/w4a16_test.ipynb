{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb9a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ['TRITON_INTERPRET'] = '1'\n",
    "import triton\n",
    "import triton.language as tl\n",
    "# import math\n",
    "\n",
    "DEVICE = triton.runtime.driver.active.get_active_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7e481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda_autotune_config():\n",
    "    configs = []\n",
    "    for num_warps, num_stages in [\n",
    "        (4, 2),\n",
    "        (4, 3),\n",
    "        (4, 4),\n",
    "        # (8, 2),\n",
    "        # (8, 4),\n",
    "    ]:\n",
    "        for GROUP_SIZE_M in [1, 4, 8, 128]:\n",
    "            for BLOCK_SIZE_M in [16]:\n",
    "                for BLOCK_SIZE_N in [32, 64, 128]:\n",
    "                    for BLOCK_SIZE_K in [32, 64, 128, 256]:\n",
    "                        configs.append(\n",
    "                            triton.Config(\n",
    "                                {\n",
    "                                    \"GROUP_SIZE_M\" : GROUP_SIZE_M,\n",
    "                                    \"BLOCK_SIZE_M\" : BLOCK_SIZE_M,\n",
    "                                    \"BLOCK_SIZE_N\" : BLOCK_SIZE_N,\n",
    "                                    \"BLOCK_SIZE_K\" : BLOCK_SIZE_K,\n",
    "                                }, \n",
    "                                num_stages=num_stages, \n",
    "                                num_warps=num_warps\n",
    "                            ),\n",
    "                        )                        \n",
    "    return configs\n",
    "    # return [triton.Config(\n",
    "    #                             {\n",
    "    #                                 \"GROUP_SIZE_M\" : 1,\n",
    "    #                                 \"BLOCK_SIZE_M\" : 32,\n",
    "    #                                 \"BLOCK_SIZE_N\" : 64,\n",
    "    #                                 \"BLOCK_SIZE_K\" : 64,\n",
    "    #                             },\n",
    "    #                             num_stages=4,\n",
    "    #                             num_warps=4\n",
    "    #                         )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225c9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a16(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    # tl.assume(pid_m == 1)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 8)\n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N) + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < N) & ((offs_bk[:, None]) < K // 8)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < N) & ((offs_bk[:, None] + (next_k_offset // 8)) < K // 8)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 8) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        # b = b.to(tl.float16)\n",
    "        # b = (b - 0x8).to(tl.float16)\n",
    "        b = (b.to(tl.float16) - 7.5) * 0.15\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a16(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 8, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    _, N = b.shape\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    triton_kernel = matmul_kernel_w4a16[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "\n",
    "    # Save compilation stages - some of the stages identified here are specific to NVIDIA devices:\n",
    "    with open('triton_IR.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['ttir'], file=f)\n",
    "    with open('triton_TTGIR.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['ttgir'], file=f)\n",
    "    with open('triton_LLVMIR.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['llir'], file=f)\n",
    "    with open('triton_PTX.ptx', 'w') as f:\n",
    "        print(triton_kernel.asm['ptx'], file=f)\n",
    "    with open('triton_cubin.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['cubin'], file=f)\n",
    "\n",
    "    return c, triton_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01d7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a16_lut(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr, lut_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    # tl.assume(pid_m == 1)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 8)\n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N) + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < N) & ((offs_bk[:, None]) < K // 8)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < N) & ((offs_bk[:, None] + (next_k_offset // 8)) < K // 8)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 8) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b_id = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "\n",
    "        # tl.assume(b_id >= 0)\n",
    "        # tl.assume(b_id < 16)\n",
    "\n",
    "        b = tl.load(lut_ptr + b_id)\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N)).to(tl.float16)\n",
    "\n",
    "        # # b = b.to(tl.float16)\n",
    "        # # b = (b - 0x8).to(tl.float16)\n",
    "        # b = (b.to(tl.float16) - 7.5) * 0.15\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a16_lut(a, b, lut):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 8, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert (len(lut.shape) == 1) & (lut.shape[0] == 16)\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    _, N = b.shape\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w4a16_lut[grid](\n",
    "        a, b, c, lut,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e39fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# M, K, N = 3 * (256,)\n",
    "\n",
    "# y_fp16 = torch.randn(M, K, dtype=torch.float16, device=\"cuda\").contiguous() / (M * K)\n",
    "# x_compressed = torch.randint(-2**31, 2**31, (K // 8, N), dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "# shifter = torch.arange(0, 8, device=\"cuda\") * 4\n",
    "\n",
    "# x_decompressed = (x_compressed[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "# x_decompressed = (x_decompressed - 0x8).reshape(K, N).to(torch.float16)\n",
    "# result_torch = y_fp16 @ x_decompressed.to(torch.float16)\n",
    "\n",
    "# result_kernel = triton_matmul_w4a16(y_fp16, x_compressed)\n",
    "\n",
    "# # result_torch\n",
    "# torch.max(torch.abs(result_torch - result_kernel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a952e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_coords = 2,0\n",
    "# print(x_compressed[(block_coords[0] * 2):(block_coords[0]+1) * 2, (block_coords[1] * 16):(block_coords[1]+1) * 16].int())\n",
    "# # print(x_decompressed[(block_coords[0] * 16):(block_coords[0]+1) * 16, (block_coords[1] * 16):(block_coords[1]+1) * 16].int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fcff4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a16_swizzle(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "\n",
    "    # tl.assume(M == 1)\n",
    "    # tl.assume(BLOCK_SIZE_M == 16)\n",
    "\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 16)\n",
    "    offs_bn = (pid_n * 2 * BLOCK_SIZE_N + tl.arange(0, 2 * BLOCK_SIZE_N)) % (2 * N)\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None]) < K // 16)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in tl.range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None] + (next_k_offset // 16)) < K // 16)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 16) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        # b = b.to(tl.float16)\n",
    "        # b = (b - 0x8).to(tl.float16)\n",
    "        b = (b.to(tl.float16) - 7.5) * 0.15\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a16_swizzle(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 16, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] // 2\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w4a16_swizzle[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4bf4d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a8_swizzle(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "\n",
    "    # tl.assume(M == 1)\n",
    "    # tl.assume(BLOCK_SIZE_M == 16)\n",
    "\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 16)\n",
    "    offs_bn = (pid_n * 2 * BLOCK_SIZE_N + tl.arange(0, 2 * BLOCK_SIZE_N)) % (2 * N)\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.int32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None]) < K // 16)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None] + (next_k_offset // 16)) < K // 16)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 16) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        b = (b - 0x8).to(tl.int8)\n",
    "        \n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    accumulator = accumulator.to(tl.float32) * 0.0001\n",
    "    accumulator = accumulator.to(tl.float16)\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator, mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a8_swizzle(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 16, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.int8\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] // 2\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w4a8_swizzle[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570600f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# M, K, N = 3 * (4096,)\n",
    "\n",
    "# y_fp16 = torch.randn(M, K, dtype=torch.float16, device=\"cuda\").contiguous() / (M * K)\n",
    "# x_compressed = torch.randint(-2**31, 2**31, (K // 16, N * 2), dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "# shifter = torch.arange(0, 8, device=\"cuda\") * 4\n",
    "# x_decompressed = (x_compressed[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "# # x_decompressed = (x_decompressed - 0x8).reshape(K, N).to(torch.float16)\n",
    "# # result_torch = y_fp16 @ x_decompressed.to(torch.float16)\n",
    "\n",
    "# result_kernel = triton_matmul_w4a16_swizzle(y_fp16, x_compressed)\n",
    "\n",
    "# # # result_torch\n",
    "# # torch.max(torch.abs(result_torch - result_kernel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7188bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w2a16_swizzle(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    # tl.assume(pid_m == 1)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 16)\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % (N)\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 16) * 2\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < N) & ((offs_bk[:, None]) < K // 16)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < N) & ((offs_bk[:, None] + (next_k_offset // 16)) < K // 16)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 16) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0x3\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        b = (b - 0x2).to(tl.float16)\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w2a16_swizzle(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 16, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1]\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w2a16_swizzle[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac41922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_int32_to_int4(bits):\n",
    "    v0 = bits & 0xF\n",
    "    v1 = (bits >> 4) & 0xF\n",
    "    v2 = (bits >> 8) & 0xF\n",
    "    v3 = (bits >> 12) & 0xF\n",
    "    v4 = (bits >> 16) & 0xF\n",
    "    v5 = (bits >> 20) & 0xF\n",
    "    v6 = (bits >> 24) & 0xF\n",
    "    v7 = (bits >> 28) & 0xF\n",
    "    \n",
    "    w = torch.stack([v0, v1, v2, v3, v4, v5, v6, v7], dim=-1) - 0x8\n",
    "    return w.reshape(bits.shape[0], bits.shape[1] * 8)\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "# M, K, N = (1, 4096, 4096)\n",
    "\n",
    "# y = torch.randn(M, K, dtype=torch.float16, device=\"cuda\") / (M * K)\n",
    "\n",
    "# # x_compressed = torch.randint(-2**31, 2**31, (K, N // 8), dtype=torch.int32, device=\"cuda\")\n",
    "# # x_decompressed = decode_int32_to_int4(x_compressed)\n",
    "# # o1 = torch.matmul(y, x_decompressed.to(torch.float16))\n",
    "# # o2 = triton_matmul_w4a16(y, x_compressed)\n",
    "\n",
    "\n",
    "# x_compressed = torch.randint(-2**31, 2**31, (K, N // 8), dtype=torch.int32, device=\"cuda\")\n",
    "# x_decompressed = decode_int32_to_int4(x_compressed)\n",
    "# o1 = torch.matmul(y, x_decompressed.to(torch.float16))\n",
    "\n",
    "# o3 = triton_matmul_w4a16_opt(y, x_compressed)\n",
    "\n",
    "# # print(matmul_kernel_.best_config)\n",
    "# # assert torch.all(torch.isclose(o1, o2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbe5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import marlin\n",
    "DEV = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "def gen_quant4(m, n, groupsize=-1):\n",
    "    maxq = 2 ** 4 - 1\n",
    "    w = torch.randn((m, n), dtype=torch.half, device=DEV)\n",
    "    if groupsize != -1:\n",
    "        w = w.reshape((-1, groupsize, n))\n",
    "        w = w.permute(1, 0, 2)\n",
    "        w = w.reshape((groupsize, -1))\n",
    "    s = torch.max(torch.abs(w), 0, keepdim=True)[0]\n",
    "    s *= 2 / maxq\n",
    "    w = torch.round(w / s).int()\n",
    "    w += (maxq + 1) // 2\n",
    "    w = torch.clamp(w, 0, maxq)\n",
    "    ref = (w - (maxq + 1) // 2).half() * s\n",
    "    if groupsize != -1:\n",
    "        def reshape(w):\n",
    "            w = w.reshape((groupsize, -1, n))\n",
    "            w = w.permute(1, 0, 2)\n",
    "            w = w.reshape((m, n)).contiguous()\n",
    "            return w\n",
    "        ref = reshape(ref)\n",
    "        w = reshape(w)\n",
    "    s = s.reshape((-1, n)).contiguous()\n",
    "    linear = nn.Linear(m, n)\n",
    "    linear.weight.data = ref.t()\n",
    "    # Workaround to test some special cases that are forbidden by the API\n",
    "    layer = marlin.Layer(256, 256, groupsize=groupsize)\n",
    "    if groupsize == -1:\n",
    "        groupsize = m\n",
    "    layer.k = m\n",
    "    layer.n = n\n",
    "    layer.groupsize = groupsize\n",
    "    layer.B = torch.empty((m // 16, n * 16 // 8), dtype=torch.int, device=DEV)\n",
    "    layer.s = torch.empty((m // groupsize, n), dtype=torch.half, device=DEV)\n",
    "    layer.pack(linear, s.t())\n",
    "    q = layer.B\n",
    "    s = layer.s\n",
    "    return ref, q, s\n",
    "\n",
    "\n",
    "def marline_matmul(A, B, scales):\n",
    "    M, K = A.shape\n",
    "    N = B.shape[-1] // 2\n",
    "\n",
    "    C = torch.zeros((M, N), dtype=torch.half, device=DEV)\n",
    "    workspace = torch.zeros(N // 128 * 16, device=DEV)\n",
    "\n",
    "    thread_k, thread_n = 128, 128\n",
    "    marlin.mul(A, B, C, scales, workspace, thread_k, thread_n, -1)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d985a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "from triton import language as tl\n",
    "\n",
    "\n",
    "def _get_cuda_autotune_config_ibm():\n",
    "    configs = []\n",
    "    for num_stages, num_warps in [\n",
    "        (2, 4),\n",
    "        (2, 8),\n",
    "        (3, 4),\n",
    "        (3, 8),\n",
    "        (4, 4),\n",
    "    ]:\n",
    "        for BLOCK_SIZE_M in [16, 32, 64, 128]:#, 128]:\n",
    "            for BLOCK_SIZE_N in [32, 64, 128]:#[64, 128]:\n",
    "                for BLOCK_SIZE_K in [16, 32]:#[16, 32]:\n",
    "                    configs.append(\n",
    "                        triton.Config(\n",
    "                            {\n",
    "                                \"group_m\" : 8,\n",
    "                                \"block_m\" : BLOCK_SIZE_M,\n",
    "                                \"block_n\" : BLOCK_SIZE_N,\n",
    "                                \"block_k\" : BLOCK_SIZE_K,\n",
    "                            }, \n",
    "                            num_stages=num_stages, \n",
    "                            num_warps=num_warps\n",
    "                        ),\n",
    "                    )                        \n",
    "    return configs\n",
    "\n",
    "\n",
    "@triton.jit()\n",
    "def swizzle_tile(pid,\n",
    "                m, n,\n",
    "                block_m: tl.constexpr, block_n: tl.constexpr, group_m: tl.constexpr):\n",
    "    \n",
    "    grid_m = tl.cdiv(m, block_m)\n",
    "    grid_n = tl.cdiv(n, block_n)\n",
    "\n",
    "    width = group_m * grid_n\n",
    "    group_id = pid // width\n",
    "    group_size = tl.minimum(grid_m - group_id * group_m, group_m)\n",
    "\n",
    "    pid_m = group_id * group_m + (pid % group_size)\n",
    "    pid_n = (pid % width) // group_size\n",
    "\n",
    "    return pid_m, pid_n\n",
    "\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=_get_cuda_autotune_config_ibm(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit()\n",
    "def matmul_split_k_kernel(a_ptr, b_ptr, c_ptr, scales_ptr, zeros_ptr,\n",
    "            stride_am, stride_ak,\n",
    "            stride_bk, stride_bn,\n",
    "            stride_cm, stride_cn,\n",
    "            stride_scales_g, stride_scales_n,\n",
    "            stride_zeros_g, stride_zeros_n,\n",
    "            groupsize,\n",
    "            m, n, k,\n",
    "            block_m: tl.constexpr, block_n: tl.constexpr, block_k: tl.constexpr,\n",
    "            group_m: tl.constexpr, split_k: tl.constexpr):\n",
    "    \n",
    "    pid = tl.program_id(axis=0)\n",
    "    pid_k = tl.program_id(axis=1)\n",
    "    total_blocks_k = tl.cdiv(k, block_k*split_k)\n",
    "\n",
    "    pid_m, pid_n = swizzle_tile(pid,\n",
    "                                m, n,\n",
    "                                block_m, block_n, group_m)\n",
    "    \n",
    "    offs_m = pid_m*block_m + tl.arange(0, block_m)\n",
    "    offs_n = pid_n*block_n + tl.arange(0, block_n)\n",
    "    offs_k = pid_k*block_k + tl.arange(0, block_k)\n",
    "\n",
    "    offs_am = tl.max_contiguous(tl.multiple_of(offs_m, block_m), block_m)\n",
    "    offs_bn = tl.max_contiguous(tl.multiple_of(offs_n, block_n), block_n)\n",
    "\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + ((offs_k[:, None] // 8) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    scales_ptrs = scales_ptr + offs_bn * stride_scales_n\n",
    "    zeros_ptrs = zeros_ptr + ((offs_bn // 8) * stride_zeros_n)\n",
    "\n",
    "    shifter = (offs_k % 8) * 4\n",
    "    zeros_shifter = (offs_bn % 8) * 4\n",
    "    \n",
    "    acc = tl.zeros((block_m, block_n), dtype=tl.float32)\n",
    "    for k in range(0, total_blocks_k):\n",
    "        \n",
    "        a = tl.load(a_ptrs)\n",
    "        b = tl.load(b_ptrs)\n",
    "        \n",
    "        g_id = (k * split_k + pid_k) // (groupsize // block_k)\n",
    "\n",
    "        ptr = scales_ptrs + g_id * stride_scales_g\n",
    "        scales = tl.load(ptr)\n",
    "        \n",
    "        ptr = zeros_ptrs + g_id * stride_zeros_g\n",
    "        zeros = tl.load(ptr) \n",
    "\n",
    "        zeros = (zeros >> zeros_shifter) & 0xF\n",
    "        zeros = (zeros + 1) * scales\n",
    "\n",
    "        b = (b >> shifter[:, None]) & 0xF\n",
    "        b = b * scales[None, :] - zeros[None, :]\n",
    "\n",
    "        acc += tl.dot(a, b)\n",
    "        a_ptrs += block_k * split_k * stride_ak\n",
    "        b_ptrs += (block_k // 8) * split_k * stride_bk\n",
    "\n",
    "    acc.to(tl.float16)\n",
    "\n",
    "    offs_m = pid_m*block_m + tl.arange(0, block_m)\n",
    "    offs_n = pid_n*block_n + tl.arange(0, block_n)\n",
    "\n",
    "    c_ptrs = c_ptr + (offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn)\n",
    "    tl.atomic_add(c_ptrs, acc, sem='release')\n",
    "\n",
    "def matmul_split_k(a, b, scales, zeros, split_k):\n",
    "\n",
    "    m, k = a.shape\n",
    "    _, n = b.shape\n",
    "    \n",
    "    quant_groupsize = 128\n",
    "    grid = lambda META: (triton.cdiv(m, META['block_m']) * triton.cdiv(n, META['block_n']), split_k)\n",
    "\n",
    "\n",
    "    # quant_groupsize = 128\n",
    "    # block_m = 16\n",
    "    # block_n = 32\n",
    "    # block_k = 128\n",
    "    # group_m = 8\n",
    "    # num_stages = 3\n",
    "    # num_warps = 4\n",
    "    # split_k = 4\n",
    "\n",
    "    # total_blocks_m = triton.cdiv(m, block_m)\n",
    "    # total_blocks_n = triton.cdiv(n, block_n)\n",
    "    # total_programs_mn = total_blocks_m * total_blocks_n\n",
    "    # total_programs_k = split_k\n",
    "    \n",
    "    # grid = (total_programs_mn, total_programs_k)\n",
    "\n",
    "\n",
    "    c = torch.zeros((m, n), device=a.device, dtype=torch.float16)\n",
    "    k = matmul_split_k_kernel[grid](a, b, c, scales, zeros,\n",
    "                              a.stride(0), a.stride(1),\n",
    "                              b.stride(0), b.stride(1),\n",
    "                              c.stride(0), c.stride(1),\n",
    "                              scales.stride(0), scales.stride(1),\n",
    "                              zeros.stride(0), zeros.stride(1),\n",
    "                              quant_groupsize,\n",
    "                              m, n, k, split_k=split_k)\n",
    "    \n",
    "    \n",
    "    # print(f\"{k.n_regs} registers used, {k.n_spills} spills, {k.shared/1000} kB shared memory\\n\")\n",
    "\n",
    "    # with open('matmul_split_k.txt', 'w') as f:\n",
    "\n",
    "    #     print(f\"{k.n_regs} registers used, {k.n_spills} spills, {k.shared/1000} kB shared memory\\n\", file=f)\n",
    "    #     print(\"IR\", k.asm['ttir'], file=f)\n",
    "    #     print(\"TTGIR\", k.asm['ttgir'], file=f)\n",
    "    #     print(\"PTX\", k.asm['ptx'], file=f)\n",
    "    #     print(f\"{k.n_regs} registers used, {k.n_spills} spills, {k.shared/1000} kB shared memory\\n\", file=f)\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def make_tensor(M, N, dtype):\n",
    "    if dtype == torch.int32:\n",
    "        # Fill with random integers for int32 type\n",
    "        res = torch.randint(low=-2147483648, high=2147483647, size=(M, N), dtype=dtype, device=\"cuda\")\n",
    "    else:\n",
    "        # Fill with normally distributed random values for other types\n",
    "        res = torch.empty((M, N), dtype=dtype, device=\"cuda\")\n",
    "        res.normal_(mean=0.0, std=0.5)\n",
    "    return res\n",
    "\n",
    "def get_ibm_quant_params(K, N, groupsize):\n",
    "    G = K // groupsize\n",
    "    b = make_tensor(K//8, N, dtype=torch.int32)\n",
    "    zeros = make_tensor(G, N//8, torch.int32)\n",
    "    scales = make_tensor(G, N, torch.float16)\n",
    "    return b, zeros, scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a76f66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[M x K x N]: [1 x 2048 x 2048]\n",
      "matmul_kernel_w4a16_swizzle: GROUP_SIZE_M: 1, BLOCK_SIZE_M: 16, BLOCK_SIZE_N: 32, BLOCK_SIZE_K: 256, num_warps: 4, num_ctas: 1, num_stages: 2, maxnreg: None\n",
      "\n",
      "[M x K x N]: [1 x 4096 x 4096]\n",
      "matmul_kernel_w4a16_swizzle: GROUP_SIZE_M: 128, BLOCK_SIZE_M: 16, BLOCK_SIZE_N: 64, BLOCK_SIZE_K: 128, num_warps: 4, num_ctas: 1, num_stages: 4, maxnreg: None\n",
      "\n",
      "[M x K x N]: [1 x 8192 x 8192]\n",
      "matmul_kernel_w4a16_swizzle: GROUP_SIZE_M: 1, BLOCK_SIZE_M: 16, BLOCK_SIZE_N: 64, BLOCK_SIZE_K: 64, num_warps: 4, num_ctas: 1, num_stages: 2, maxnreg: None\n",
      "matmul-performance:\n",
      "        K    M       N  torch_fp16  triton_w4a16_swizzle  marline_w4a16\n",
      "0  2048.0  1.0  2048.0    0.170667              0.372364       0.455111\n",
      "1  4096.0  1.0  4096.0    0.244537              0.574877       0.840205\n",
      "2  8192.0  1.0  8192.0    0.304819              0.724155       1.110780\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BS = 1\n",
    "# sizes = [1024, 2048, 4096, 8192, 16384]\n",
    "sizes = [2048, 4096, 8192]\n",
    "\n",
    "configs = []\n",
    "configs.append(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"K\", \"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "        # x_vals=[3 * (size,) for size in sizes],\n",
    "        x_vals=[(size, BS, size) for size in sizes],\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        # Don't compare to cublas for fp8 cases as torch.matmul doesn't support fp8 at the moment.\n",
    "        line_vals=[\n",
    "            \"torch_fp16\",\n",
    "            \"triton_w4a16_swizzle\",\n",
    "            # \"triton_w4a8_swizzle\",\n",
    "            # \"triton_w4a16_lut\",\n",
    "            # \"triton_w4a16\",\n",
    "            # \"triton_w2a16_swizzle\",\n",
    "            \"marline_w4a16\",\n",
    "            # \"ibm_w4a16_k4\"\n",
    "            ],\n",
    "        line_names=[\n",
    "            \"torch_fp16\",\n",
    "            \"triton_w4a16_swizzle\",\n",
    "            # \"triton_w4a8_swizzle\",\n",
    "            # \"triton_w4a16_lut\",\n",
    "            # \"triton_w4a16\",\n",
    "            # \"triton_w4a16_swizzle\",\n",
    "            # \"triton_w2a16_swizzle\",\n",
    "            \"marline_w4a16\",\n",
    "            # \"ibm_w4a16_k4\"\n",
    "            ],\n",
    "        ylabel=\"TFLOPS\",  # Label name for the y-axis\n",
    "        xlabel=\"Matrix size\",\n",
    "        plot_name=\"matmul-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={},\n",
    "    ))\n",
    "\n",
    "\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, K, N, provider):\n",
    "    y_fp16 = torch.randn(M, K, dtype=torch.float16, device=\"cuda\") / (M * K)\n",
    "    y_int8 = torch.randint(-128, 128, (M, K), dtype=torch.int8, device=\"cuda\")\n",
    "    \n",
    "    x_compressed = torch.randint(-2**31, 2**31, (K // 8, N), dtype=torch.int32, device=\"cuda\")\n",
    "    \n",
    "    # decompress\n",
    "    shifter = torch.arange(0, 8, device=\"cuda\") * 4\n",
    "    x_decompressed = (x_compressed[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "    x_decompressed = (x_decompressed - 0x8).reshape(K, N).to(torch.float16).contiguous()\n",
    "    \n",
    "    # swizzled\n",
    "    x_compressed_swizzle_4bit = torch.randint(-2**31, 2**31, (K // 16, N * 2), dtype=torch.int32, device=\"cuda\")\n",
    "    x_compressed_swizzle_2bit = torch.randint(-2**31, 2**31, (K // 16, N), dtype=torch.int32, device=\"cuda\")\n",
    "    # x_compressed_swizzle_4bit_transposed = torch.randint(-2**31, 2**31, (N * 2, K // 16), dtype=torch.int32, device=\"cuda\").T\n",
    "    \n",
    "    # lut\n",
    "    # x_compressed_lut = torch.randint(0, 2**32, (K // 8, N), dtype=torch.uint32, device=\"cuda\")\n",
    "    # lut = torch.randn(16, dtype=torch.float16).cuda()\n",
    "\n",
    "    # # marline\n",
    "    _, x_compressed_marline, scales_marline = gen_quant4(K, N, groupsize=-1)\n",
    "    \n",
    "    # # imb kernel\n",
    "    # b, zeros, scales = get_ibm_quant_params(K, N, groupsize=128)\n",
    "\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == \"torch_fp16\":\n",
    "        print(f\"\\n[M x K x N]: [{M} x {K} x {N}]\")\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(y_fp16, x_decompressed), quantiles=quantiles)\n",
    "    \n",
    "    if provider == \"triton_w4a16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a16(y_fp16, x_compressed), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a16:\", matmul_kernel_w4a16.best_config)\n",
    "    \n",
    "    if provider == \"triton_w4a16_lut\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a16_lut(y_fp16, x_compressed, lut), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a16_lut:\", matmul_kernel_w4a16_lut.best_config)\n",
    "    \n",
    "    if provider == \"triton_w2a16_swizzle\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w2a16_swizzle(y_fp16, x_compressed_swizzle_2bit), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w2a16_swizzle:\", matmul_kernel_w2a16_swizzle.best_config)\n",
    "    \n",
    "    if provider == \"triton_w4a8_swizzle\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a8_swizzle(y_int8, x_compressed_swizzle_4bit), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a8_swizzle:\", matmul_kernel_w4a8_swizzle.best_config)\n",
    "\n",
    "    if provider == \"triton_w4a16_swizzle\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a16_swizzle(y_fp16, x_compressed_swizzle_4bit), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a16_swizzle:\", matmul_kernel_w4a16_swizzle.best_config)\n",
    "\n",
    "    if provider == \"marline_w4a16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: marline_matmul(y_fp16, x_compressed_marline, scales_marline), quantiles=quantiles)\n",
    "    \n",
    "    if provider == \"ibm_w4a16_k4\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul_split_k(y_fp16, b, scales, zeros, split_k=4), quantiles=quantiles)\n",
    "\n",
    "    perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n",
    "\n",
    "benchmark.run(show_plots=False, print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70542b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87593c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
