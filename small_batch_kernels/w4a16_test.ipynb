{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb9a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "# os.environ['TRITON_INTERPRET'] = '1'\n",
    "import triton\n",
    "import triton.language as tl\n",
    "# import math\n",
    "\n",
    "DEVICE = triton.runtime.driver.active.get_active_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7e481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda_autotune_config():\n",
    "    configs = []\n",
    "    for num_warps, num_stages in [\n",
    "        (4, 2),\n",
    "        (4, 3),\n",
    "        (4, 4),\n",
    "        # (8, 2),\n",
    "        # (8, 4),\n",
    "    ]:\n",
    "        for GROUP_SIZE_M in [1, 4, 8, 128]:\n",
    "            for BLOCK_SIZE_M in [16]:\n",
    "                for BLOCK_SIZE_N in [32, 64, 128]:\n",
    "                    for BLOCK_SIZE_K in [32, 64, 128, 256]:\n",
    "                        configs.append(\n",
    "                            triton.Config(\n",
    "                                {\n",
    "                                    \"GROUP_SIZE_M\" : GROUP_SIZE_M,\n",
    "                                    \"BLOCK_SIZE_M\" : BLOCK_SIZE_M,\n",
    "                                    \"BLOCK_SIZE_N\" : BLOCK_SIZE_N,\n",
    "                                    \"BLOCK_SIZE_K\" : BLOCK_SIZE_K,\n",
    "                                }, \n",
    "                                num_stages=num_stages, \n",
    "                                num_warps=num_warps\n",
    "                            ),\n",
    "                        )                        \n",
    "    return configs\n",
    "    # return [triton.Config(\n",
    "    #                             {\n",
    "    #                                 \"GROUP_SIZE_M\" : 1,\n",
    "    #                                 \"BLOCK_SIZE_M\" : 32,\n",
    "    #                                 \"BLOCK_SIZE_N\" : 64,\n",
    "    #                                 \"BLOCK_SIZE_K\" : 64,\n",
    "    #                             },\n",
    "    #                             num_stages=4,\n",
    "    #                             num_warps=4\n",
    "    #                         )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225c9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a16(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    # tl.assume(pid_m == 1)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 8)\n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N) + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < N) & ((offs_bk[:, None]) < K // 8)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < N) & ((offs_bk[:, None] + (next_k_offset // 8)) < K // 8)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 8) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        # b = b.to(tl.float16)\n",
    "        # b = (b - 0x8).to(tl.float16)\n",
    "        b = (b.to(tl.float16) - 7.5) * 0.15\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a16(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 8, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    _, N = b.shape\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    triton_kernel = matmul_kernel_w4a16[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "\n",
    "    # Save compilation stages - some of the stages identified here are specific to NVIDIA devices:\n",
    "    with open('triton_IR.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['ttir'], file=f)\n",
    "    with open('triton_TTGIR.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['ttgir'], file=f)\n",
    "    with open('triton_LLVMIR.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['llir'], file=f)\n",
    "    with open('triton_PTX.ptx', 'w') as f:\n",
    "        print(triton_kernel.asm['ptx'], file=f)\n",
    "    with open('triton_cubin.txt', 'w') as f:\n",
    "        print(triton_kernel.asm['cubin'], file=f)\n",
    "\n",
    "    return c, triton_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01d7a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a16_lut(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr, lut_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    # tl.assume(pid_m == 1)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 8)\n",
    "    offs_bn = (pid_n * (BLOCK_SIZE_N) + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < N) & ((offs_bk[:, None]) < K // 8)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < N) & ((offs_bk[:, None] + (next_k_offset // 8)) < K // 8)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 8) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b_id = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "\n",
    "        # tl.assume(b_id >= 0)\n",
    "        # tl.assume(b_id < 16)\n",
    "\n",
    "        b = tl.load(lut_ptr + b_id)\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N)).to(tl.float16)\n",
    "\n",
    "        # # b = b.to(tl.float16)\n",
    "        # # b = (b - 0x8).to(tl.float16)\n",
    "        # b = (b.to(tl.float16) - 7.5) * 0.15\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a16_lut(a, b, lut):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 8, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert (len(lut.shape) == 1) & (lut.shape[0] == 16)\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    _, N = b.shape\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w4a16_lut[grid](\n",
    "        a, b, c, lut,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e39fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# M, K, N = 3 * (256,)\n",
    "\n",
    "# y_fp16 = torch.randn(M, K, dtype=torch.float16, device=\"cuda\").contiguous() / (M * K)\n",
    "# x_compressed = torch.randint(-2**31, 2**31, (K // 8, N), dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "# shifter = torch.arange(0, 8, device=\"cuda\") * 4\n",
    "\n",
    "# x_decompressed = (x_compressed[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "# x_decompressed = (x_decompressed - 0x8).reshape(K, N).to(torch.float16)\n",
    "# result_torch = y_fp16 @ x_decompressed.to(torch.float16)\n",
    "\n",
    "# result_kernel = triton_matmul_w4a16(y_fp16, x_compressed)\n",
    "\n",
    "# # result_torch\n",
    "# torch.max(torch.abs(result_torch - result_kernel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a952e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_coords = 2,0\n",
    "# print(x_compressed[(block_coords[0] * 2):(block_coords[0]+1) * 2, (block_coords[1] * 16):(block_coords[1]+1) * 16].int())\n",
    "# # print(x_decompressed[(block_coords[0] * 16):(block_coords[0]+1) * 16, (block_coords[1] * 16):(block_coords[1]+1) * 16].int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fcff4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a16_swizzle(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "\n",
    "    # tl.assume(M == 1)\n",
    "    # tl.assume(BLOCK_SIZE_M == 16)\n",
    "\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 16)\n",
    "    offs_bn = (pid_n * 2 * BLOCK_SIZE_N + tl.arange(0, 2 * BLOCK_SIZE_N)) % (2 * N)\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None]) < K // 16)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in tl.range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None] + (next_k_offset // 16)) < K // 16)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 16) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        # b = b.to(tl.float16)\n",
    "        # b = (b - 0x8).to(tl.float16)\n",
    "        b = (b.to(tl.float16) - 7.5) * 0.15\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a16_swizzle(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 16, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] // 2\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w4a16_swizzle[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4bf4d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w4a8_swizzle(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "\n",
    "    # tl.assume(M == 1)\n",
    "    # tl.assume(BLOCK_SIZE_M == 16)\n",
    "\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 16)\n",
    "    offs_bn = (pid_n * 2 * BLOCK_SIZE_N + tl.arange(0, 2 * BLOCK_SIZE_N)) % (2 * N)\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 8) * 4\n",
    "\n",
    "    accumulator_dtype = tl.int32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None]) < K // 16)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < 2 * N) & ((offs_bk[:, None] + (next_k_offset // 16)) < K // 16)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 16) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        b = (b - 0x8).to(tl.int8)\n",
    "        \n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    accumulator = accumulator.to(tl.float32) * 0.0001\n",
    "    accumulator = accumulator.to(tl.float16)\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator, mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w4a8_swizzle(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 16, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.int8\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1] // 2\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w4a8_swizzle[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570600f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# M, K, N = 3 * (4096,)\n",
    "\n",
    "# y_fp16 = torch.randn(M, K, dtype=torch.float16, device=\"cuda\").contiguous() / (M * K)\n",
    "# x_compressed = torch.randint(-2**31, 2**31, (K // 16, N * 2), dtype=torch.int32, device=\"cuda\")\n",
    "\n",
    "# shifter = torch.arange(0, 8, device=\"cuda\") * 4\n",
    "# x_decompressed = (x_compressed[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "# # x_decompressed = (x_decompressed - 0x8).reshape(K, N).to(torch.float16)\n",
    "# # result_torch = y_fp16 @ x_decompressed.to(torch.float16)\n",
    "\n",
    "# result_kernel = triton_matmul_w4a16_swizzle(y_fp16, x_compressed)\n",
    "\n",
    "# # # result_torch\n",
    "# # torch.max(torch.abs(result_torch - result_kernel))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7188bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel_w2a16_swizzle(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    # tl.assume(pid_m == 1)\n",
    "\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    \n",
    "    offs_bk = tl.arange(0, BLOCK_SIZE_K // 16)\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % (N)\n",
    "    b_ptrs = b_ptr + ((offs_bk[:, None]) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    shifter = tl.arange(0, 16) * 2\n",
    "\n",
    "    accumulator_dtype = tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "\n",
    "    a_mask0 = (offs_am[:, None] < M) & (offs_k[None, :] < K)\n",
    "    b_mask0 = (offs_bn[None, :] < N) & ((offs_bk[:, None]) < K // 16)\n",
    "    a = tl.load(a_ptrs, mask=a_mask0, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "    b_bits = tl.load(b_ptrs, mask=b_mask0, other=0)#, eviction_policy=\"evict_first\")\n",
    "    for k_idx in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        next_k_offset = (k_idx + 1) * BLOCK_SIZE_K\n",
    "        \n",
    "        if k_idx + 1 < tl.cdiv(K, BLOCK_SIZE_K):\n",
    "            a_next_mask = (offs_am[:, None] < M) & (offs_k[None, :] + next_k_offset < K)\n",
    "            b_next_mask = (offs_bn[None, :] < N) & ((offs_bk[:, None] + (next_k_offset // 16)) < K // 16)\n",
    "            a_next = tl.load(a_ptrs + next_k_offset * stride_ak, mask=a_next_mask, other=0.0)#, eviction_policy=\"evict_last\")\n",
    "            b_bits_next = tl.load(b_ptrs + (next_k_offset // 16) * stride_bk, mask=b_next_mask, other=0)#, eviction_policy=\"evict_first\")\n",
    "        else:\n",
    "            a_next = tl.zeros_like(a)\n",
    "            b_bits_next = tl.zeros_like(b_bits)\n",
    "\n",
    "        b = (b_bits[:, None, :] >> shifter[None, :, None]) & 0x3\n",
    "        b = tl.reshape(b, (BLOCK_SIZE_K, BLOCK_SIZE_N))\n",
    "        b = (b - 0x2).to(tl.float16)\n",
    "\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "\n",
    "        a = a_next\n",
    "        b_bits = b_bits_next\n",
    "\n",
    "\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, accumulator.to(tl.float16), mask=c_mask)\n",
    "\n",
    "\n",
    "def triton_matmul_w2a16_swizzle(a, b):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0] * 16, \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "\n",
    "    assert a.dtype == torch.float16\n",
    "    assert b.dtype == torch.int32\n",
    "    \n",
    "    M, K = a.shape\n",
    "    N = b.shape[1]\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel_w2a16_swizzle[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "    )\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac41922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_int32_to_int4(bits):\n",
    "    v0 = bits & 0xF\n",
    "    v1 = (bits >> 4) & 0xF\n",
    "    v2 = (bits >> 8) & 0xF\n",
    "    v3 = (bits >> 12) & 0xF\n",
    "    v4 = (bits >> 16) & 0xF\n",
    "    v5 = (bits >> 20) & 0xF\n",
    "    v6 = (bits >> 24) & 0xF\n",
    "    v7 = (bits >> 28) & 0xF\n",
    "    \n",
    "    w = torch.stack([v0, v1, v2, v3, v4, v5, v6, v7], dim=-1) - 0x8\n",
    "    return w.reshape(bits.shape[0], bits.shape[1] * 8)\n",
    "\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "# M, K, N = (1, 4096, 4096)\n",
    "\n",
    "# y = torch.randn(M, K, dtype=torch.float16, device=\"cuda\") / (M * K)\n",
    "\n",
    "# # x_compressed = torch.randint(-2**31, 2**31, (K, N // 8), dtype=torch.int32, device=\"cuda\")\n",
    "# # x_decompressed = decode_int32_to_int4(x_compressed)\n",
    "# # o1 = torch.matmul(y, x_decompressed.to(torch.float16))\n",
    "# # o2 = triton_matmul_w4a16(y, x_compressed)\n",
    "\n",
    "\n",
    "# x_compressed = torch.randint(-2**31, 2**31, (K, N // 8), dtype=torch.int32, device=\"cuda\")\n",
    "# x_decompressed = decode_int32_to_int4(x_compressed)\n",
    "# o1 = torch.matmul(y, x_decompressed.to(torch.float16))\n",
    "\n",
    "# o3 = triton_matmul_w4a16_opt(y, x_compressed)\n",
    "\n",
    "# # print(matmul_kernel_.best_config)\n",
    "# # assert torch.all(torch.isclose(o1, o2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbe5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import marlin\n",
    "DEV = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "def gen_quant4(m, n, groupsize=-1):\n",
    "    maxq = 2 ** 4 - 1\n",
    "    w = torch.randn((m, n), dtype=torch.half, device=DEV)\n",
    "    if groupsize != -1:\n",
    "        w = w.reshape((-1, groupsize, n))\n",
    "        w = w.permute(1, 0, 2)\n",
    "        w = w.reshape((groupsize, -1))\n",
    "    s = torch.max(torch.abs(w), 0, keepdim=True)[0]\n",
    "    s *= 2 / maxq\n",
    "    w = torch.round(w / s).int()\n",
    "    w += (maxq + 1) // 2\n",
    "    w = torch.clamp(w, 0, maxq)\n",
    "    ref = (w - (maxq + 1) // 2).half() * s\n",
    "    if groupsize != -1:\n",
    "        def reshape(w):\n",
    "            w = w.reshape((groupsize, -1, n))\n",
    "            w = w.permute(1, 0, 2)\n",
    "            w = w.reshape((m, n)).contiguous()\n",
    "            return w\n",
    "        ref = reshape(ref)\n",
    "        w = reshape(w)\n",
    "    s = s.reshape((-1, n)).contiguous()\n",
    "    linear = nn.Linear(m, n)\n",
    "    linear.weight.data = ref.t()\n",
    "    # Workaround to test some special cases that are forbidden by the API\n",
    "    layer = marlin.Layer(256, 256, groupsize=groupsize)\n",
    "    if groupsize == -1:\n",
    "        groupsize = m\n",
    "    layer.k = m\n",
    "    layer.n = n\n",
    "    layer.groupsize = groupsize\n",
    "    layer.B = torch.empty((m // 16, n * 16 // 8), dtype=torch.int, device=DEV)\n",
    "    layer.s = torch.empty((m // groupsize, n), dtype=torch.half, device=DEV)\n",
    "    layer.pack(linear, s.t())\n",
    "    q = layer.B\n",
    "    s = layer.s\n",
    "    return ref, q, s\n",
    "\n",
    "\n",
    "def marline_matmul(A, B, scales):\n",
    "    M, K = A.shape\n",
    "    N = B.shape[-1] // 2\n",
    "\n",
    "    C = torch.zeros((M, N), dtype=torch.half, device=DEV)\n",
    "    workspace = torch.zeros(N // 128 * 16, device=DEV)\n",
    "\n",
    "    thread_k, thread_n = 128, 128\n",
    "    marlin.mul(A, B, C, scales, workspace, thread_k, thread_n, -1)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d985a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "from triton import language as tl\n",
    "\n",
    "\n",
    "def _get_cuda_autotune_config_ibm():\n",
    "    configs = []\n",
    "    for num_stages, num_warps in [\n",
    "        (2, 4),\n",
    "        (2, 8),\n",
    "        (3, 4),\n",
    "        (3, 8),\n",
    "        (4, 4),\n",
    "    ]:\n",
    "        for BLOCK_SIZE_M in [16, 32, 64, 128]:#, 128]:\n",
    "            for BLOCK_SIZE_N in [32, 64, 128]:#[64, 128]:\n",
    "                for BLOCK_SIZE_K in [16, 32]:#[16, 32]:\n",
    "                    configs.append(\n",
    "                        triton.Config(\n",
    "                            {\n",
    "                                \"group_m\" : 8,\n",
    "                                \"block_m\" : BLOCK_SIZE_M,\n",
    "                                \"block_n\" : BLOCK_SIZE_N,\n",
    "                                \"block_k\" : BLOCK_SIZE_K,\n",
    "                            }, \n",
    "                            num_stages=num_stages, \n",
    "                            num_warps=num_warps\n",
    "                        ),\n",
    "                    )                        \n",
    "    return configs\n",
    "\n",
    "\n",
    "@triton.jit()\n",
    "def swizzle_tile(pid,\n",
    "                m, n,\n",
    "                block_m: tl.constexpr, block_n: tl.constexpr, group_m: tl.constexpr):\n",
    "    \n",
    "    grid_m = tl.cdiv(m, block_m)\n",
    "    grid_n = tl.cdiv(n, block_n)\n",
    "\n",
    "    width = group_m * grid_n\n",
    "    group_id = pid // width\n",
    "    group_size = tl.minimum(grid_m - group_id * group_m, group_m)\n",
    "\n",
    "    pid_m = group_id * group_m + (pid % group_size)\n",
    "    pid_n = (pid % width) // group_size\n",
    "\n",
    "    return pid_m, pid_n\n",
    "\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=_get_cuda_autotune_config_ibm(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit()\n",
    "def matmul_split_k_kernel(a_ptr, b_ptr, c_ptr, scales_ptr, zeros_ptr,\n",
    "            stride_am, stride_ak,\n",
    "            stride_bk, stride_bn,\n",
    "            stride_cm, stride_cn,\n",
    "            stride_scales_g, stride_scales_n,\n",
    "            stride_zeros_g, stride_zeros_n,\n",
    "            groupsize,\n",
    "            m, n, k,\n",
    "            block_m: tl.constexpr, block_n: tl.constexpr, block_k: tl.constexpr,\n",
    "            group_m: tl.constexpr, split_k: tl.constexpr):\n",
    "    \n",
    "    pid = tl.program_id(axis=0)\n",
    "    pid_k = tl.program_id(axis=1)\n",
    "    total_blocks_k = tl.cdiv(k, block_k*split_k)\n",
    "\n",
    "    pid_m, pid_n = swizzle_tile(pid,\n",
    "                                m, n,\n",
    "                                block_m, block_n, group_m)\n",
    "    \n",
    "    offs_m = pid_m*block_m + tl.arange(0, block_m)\n",
    "    offs_n = pid_n*block_n + tl.arange(0, block_n)\n",
    "    offs_k = pid_k*block_k + tl.arange(0, block_k)\n",
    "\n",
    "    offs_am = tl.max_contiguous(tl.multiple_of(offs_m, block_m), block_m)\n",
    "    offs_bn = tl.max_contiguous(tl.multiple_of(offs_n, block_n), block_n)\n",
    "\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + ((offs_k[:, None] // 8) * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    scales_ptrs = scales_ptr + offs_bn * stride_scales_n\n",
    "    zeros_ptrs = zeros_ptr + ((offs_bn // 8) * stride_zeros_n)\n",
    "\n",
    "    shifter = (offs_k % 8) * 4\n",
    "    zeros_shifter = (offs_bn % 8) * 4\n",
    "    \n",
    "    acc = tl.zeros((block_m, block_n), dtype=tl.float32)\n",
    "    for k in range(0, total_blocks_k):\n",
    "        \n",
    "        a = tl.load(a_ptrs)\n",
    "        b = tl.load(b_ptrs)\n",
    "        \n",
    "        g_id = (k * split_k + pid_k) // (groupsize // block_k)\n",
    "\n",
    "        ptr = scales_ptrs + g_id * stride_scales_g\n",
    "        scales = tl.load(ptr)\n",
    "        \n",
    "        ptr = zeros_ptrs + g_id * stride_zeros_g\n",
    "        zeros = tl.load(ptr) \n",
    "\n",
    "        zeros = (zeros >> zeros_shifter) & 0xF\n",
    "        zeros = (zeros + 1) * scales\n",
    "\n",
    "        b = (b >> shifter[:, None]) & 0xF\n",
    "        b = b * scales[None, :] - zeros[None, :]\n",
    "\n",
    "        acc += tl.dot(a, b)\n",
    "        a_ptrs += block_k * split_k * stride_ak\n",
    "        b_ptrs += (block_k // 8) * split_k * stride_bk\n",
    "\n",
    "    acc.to(tl.float16)\n",
    "\n",
    "    offs_m = pid_m*block_m + tl.arange(0, block_m)\n",
    "    offs_n = pid_n*block_n + tl.arange(0, block_n)\n",
    "\n",
    "    c_ptrs = c_ptr + (offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn)\n",
    "    tl.atomic_add(c_ptrs, acc, sem='release')\n",
    "\n",
    "def matmul_split_k(a, b, scales, zeros, split_k):\n",
    "\n",
    "    m, k = a.shape\n",
    "    _, n = b.shape\n",
    "    \n",
    "    quant_groupsize = 128\n",
    "    grid = lambda META: (triton.cdiv(m, META['block_m']) * triton.cdiv(n, META['block_n']), split_k)\n",
    "\n",
    "\n",
    "    # quant_groupsize = 128\n",
    "    # block_m = 16\n",
    "    # block_n = 32\n",
    "    # block_k = 128\n",
    "    # group_m = 8\n",
    "    # num_stages = 3\n",
    "    # num_warps = 4\n",
    "    # split_k = 4\n",
    "\n",
    "    # total_blocks_m = triton.cdiv(m, block_m)\n",
    "    # total_blocks_n = triton.cdiv(n, block_n)\n",
    "    # total_programs_mn = total_blocks_m * total_blocks_n\n",
    "    # total_programs_k = split_k\n",
    "    \n",
    "    # grid = (total_programs_mn, total_programs_k)\n",
    "\n",
    "\n",
    "    c = torch.zeros((m, n), device=a.device, dtype=torch.float16)\n",
    "    k = matmul_split_k_kernel[grid](a, b, c, scales, zeros,\n",
    "                              a.stride(0), a.stride(1),\n",
    "                              b.stride(0), b.stride(1),\n",
    "                              c.stride(0), c.stride(1),\n",
    "                              scales.stride(0), scales.stride(1),\n",
    "                              zeros.stride(0), zeros.stride(1),\n",
    "                              quant_groupsize,\n",
    "                              m, n, k, split_k=split_k)\n",
    "    \n",
    "    \n",
    "    # print(f\"{k.n_regs} registers used, {k.n_spills} spills, {k.shared/1000} kB shared memory\\n\")\n",
    "\n",
    "    # with open('matmul_split_k.txt', 'w') as f:\n",
    "\n",
    "    #     print(f\"{k.n_regs} registers used, {k.n_spills} spills, {k.shared/1000} kB shared memory\\n\", file=f)\n",
    "    #     print(\"IR\", k.asm['ttir'], file=f)\n",
    "    #     print(\"TTGIR\", k.asm['ttgir'], file=f)\n",
    "    #     print(\"PTX\", k.asm['ptx'], file=f)\n",
    "    #     print(f\"{k.n_regs} registers used, {k.n_spills} spills, {k.shared/1000} kB shared memory\\n\", file=f)\n",
    "\n",
    "    return c\n",
    "\n",
    "\n",
    "def make_tensor(M, N, dtype):\n",
    "    if dtype == torch.int32:\n",
    "        # Fill with random integers for int32 type\n",
    "        res = torch.randint(low=-2147483648, high=2147483647, size=(M, N), dtype=dtype, device=\"cuda\")\n",
    "    else:\n",
    "        # Fill with normally distributed random values for other types\n",
    "        res = torch.empty((M, N), dtype=dtype, device=\"cuda\")\n",
    "        res.normal_(mean=0.0, std=0.5)\n",
    "    return res\n",
    "\n",
    "def get_ibm_quant_params(K, N, groupsize):\n",
    "    G = K // groupsize\n",
    "    b = make_tensor(K//8, N, dtype=torch.int32)\n",
    "    zeros = make_tensor(G, N//8, torch.int32)\n",
    "    scales = make_tensor(G, N, torch.float16)\n",
    "    return b, zeros, scales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76f66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[M x K x N]: [1 x 2048 x 2048]\n"
     ]
    }
   ],
   "source": [
    "BS = 1\n",
    "# sizes = [1024, 2048, 4096, 8192, 16384]\n",
    "sizes = [2048, 4096, 8192]\n",
    "\n",
    "configs = []\n",
    "configs.append(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"K\", \"M\", \"N\"],  # Argument names to use as an x-axis for the plot\n",
    "        # x_vals=[3 * (size,) for size in sizes],\n",
    "        x_vals=[(size, BS, size) for size in sizes],\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        # Don't compare to cublas for fp8 cases as torch.matmul doesn't support fp8 at the moment.\n",
    "        line_vals=[\n",
    "            \"torch_fp16\",\n",
    "            \"triton_w4a16_swizzle\",\n",
    "            # \"triton_w4a8_swizzle\",\n",
    "            # \"triton_w4a16_lut\",\n",
    "            \"triton_w4a16\",\n",
    "            # \"triton_w2a16_swizzle\",\n",
    "            \"marline_w4a16\",\n",
    "            # \"ibm_w4a16_k4\"\n",
    "            ],\n",
    "        line_names=[\n",
    "            \"torch_fp16\",\n",
    "            \"triton_w4a16_swizzle\",\n",
    "            # \"triton_w4a8_swizzle\",\n",
    "            # \"triton_w4a16_lut\",\n",
    "            \"triton_w4a16\",\n",
    "            # \"triton_w4a16_swizzle\",\n",
    "            # \"triton_w2a16_swizzle\",\n",
    "            \"marline_w4a16\",\n",
    "            # \"ibm_w4a16_k4\"\n",
    "            ],\n",
    "        ylabel=\"TFLOPS\",  # Label name for the y-axis\n",
    "        xlabel=\"Matrix size\",\n",
    "        plot_name=\"matmul-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={},\n",
    "    ))\n",
    "\n",
    "\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, K, N, provider):\n",
    "    y_fp16 = torch.randn(M, K, dtype=torch.float16, device=\"cuda\") / (M * K)\n",
    "    y_int8 = torch.randint(-128, 128, (M, K), dtype=torch.int8, device=\"cuda\")\n",
    "    \n",
    "    x_compressed = torch.randint(-2**31, 2**31, (K // 8, N), dtype=torch.int32, device=\"cuda\")\n",
    "    \n",
    "    # decompress\n",
    "    shifter = torch.arange(0, 8, device=\"cuda\") * 4\n",
    "    x_decompressed = (x_compressed[:, None, :] >> shifter[None, :, None]) & 0xF\n",
    "    x_decompressed = (x_decompressed - 0x8).reshape(K, N).to(torch.float16).contiguous()\n",
    "    \n",
    "    # swizzled\n",
    "    x_compressed_swizzle_4bit = torch.randint(-2**31, 2**31, (K // 16, N * 2), dtype=torch.int32, device=\"cuda\")\n",
    "    x_compressed_swizzle_2bit = torch.randint(-2**31, 2**31, (K // 16, N), dtype=torch.int32, device=\"cuda\")\n",
    "    # x_compressed_swizzle_4bit_transposed = torch.randint(-2**31, 2**31, (N * 2, K // 16), dtype=torch.int32, device=\"cuda\").T\n",
    "    \n",
    "    # lut\n",
    "    # x_compressed_lut = torch.randint(0, 2**32, (K // 8, N), dtype=torch.uint32, device=\"cuda\")\n",
    "    # lut = torch.randn(16, dtype=torch.float16).cuda()\n",
    "\n",
    "    # # marline\n",
    "    _, x_compressed_marline, scales_marline = gen_quant4(K, N, groupsize=-1)\n",
    "    \n",
    "    # # imb kernel\n",
    "    # b, zeros, scales = get_ibm_quant_params(K, N, groupsize=128)\n",
    "\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == \"torch_fp16\":\n",
    "        print(f\"\\n[M x K x N]: [{M} x {K} x {N}]\")\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(y_fp16, x_decompressed), quantiles=quantiles)\n",
    "    \n",
    "    if provider == \"triton_w4a16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a16(y_fp16, x_compressed), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a16:\", matmul_kernel_w4a16.best_config)\n",
    "    \n",
    "    if provider == \"triton_w4a16_lut\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a16_lut(y_fp16, x_compressed, lut), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a16_lut:\", matmul_kernel_w4a16_lut.best_config)\n",
    "    \n",
    "    if provider == \"triton_w2a16_swizzle\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w2a16_swizzle(y_fp16, x_compressed_swizzle_2bit), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w2a16_swizzle:\", matmul_kernel_w2a16_swizzle.best_config)\n",
    "    \n",
    "    if provider == \"triton_w4a8_swizzle\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a8_swizzle(y_int8, x_compressed_swizzle_4bit), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a8_swizzle:\", matmul_kernel_w4a8_swizzle.best_config)\n",
    "\n",
    "    if provider == \"triton_w4a16_swizzle\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: triton_matmul_w4a16_swizzle(y_fp16, x_compressed_swizzle_4bit), quantiles=quantiles)\n",
    "        print(\"matmul_kernel_w4a16_swizzle:\", matmul_kernel_w4a16_swizzle.best_config)\n",
    "\n",
    "    if provider == \"marline_w4a16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: marline_matmul(y_fp16, x_compressed_marline, scales_marline), quantiles=quantiles)\n",
    "    \n",
    "    if provider == \"ibm_w4a16_k4\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul_split_k(y_fp16, b, scales, zeros, split_k=4), quantiles=quantiles)\n",
    "\n",
    "    perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n",
    "\n",
    "benchmark.run(show_plots=False, print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70542b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57953f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# def _get_perms():\n",
    "#     perm = []\n",
    "#     for i in range(32):\n",
    "#         perm1 = []\n",
    "#         col = i // 4\n",
    "#         for block in [0, 1]:\n",
    "#             for row in [\n",
    "#                 2 * (i % 4),\n",
    "#                 2 * (i % 4) + 1,\n",
    "#                 2 * (i % 4 + 4),\n",
    "#                 2 * (i % 4 + 4) + 1\n",
    "#             ]:\n",
    "#                 perm1.append(16 * row + col + 8 * block)\n",
    "#         for j in range(4):\n",
    "#             perm.extend([p + 256 * j for p in perm1])\n",
    "\n",
    "#     perm = np.array(perm)\n",
    "#     interleave = np.array([0, 2, 4, 6, 1, 3, 5, 7])\n",
    "#     perm = perm.reshape((-1, 8))[:, interleave].ravel()\n",
    "#     perm = torch.from_numpy(perm)\n",
    "#     scale_perm = []\n",
    "#     for i in range(8):\n",
    "#         scale_perm.extend([i + 8 * j for j in range(8)])\n",
    "#     scale_perm_single = []\n",
    "#     for i in range(4):\n",
    "#         scale_perm_single.extend([2 * i + j for j in [0, 1, 8, 9, 16, 17, 24, 25]])\n",
    "#     return perm, scale_perm, scale_perm_single\n",
    "\n",
    "# _perm, _scale_perm, _scale_perm_single = _get_perms()\n",
    "\n",
    "# print(_perm[:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87593c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
