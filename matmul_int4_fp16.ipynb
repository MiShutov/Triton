{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbe9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "# os.environ['TRITON_INTERPRET'] = '1'\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import math\n",
    "\n",
    "DEVICE = triton.runtime.driver.active.get_active_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2b2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuda_autotune_config():\n",
    "    return [\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3,\n",
    "                      num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5,\n",
    "                      num_warps=2),\n",
    "        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5,\n",
    "                      num_warps=2),\n",
    "        # Good config for fp8 inputs.\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=3,\n",
    "                      num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=3,\n",
    "                      num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4)\n",
    "    ]\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=['M', 'N', 'K'],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_kernel(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,\n",
    "        # Matrix dimensions\n",
    "        M, N, K,\n",
    "        # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "        # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`\n",
    "        # by to get the element one row down (A has M rows).\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "        ACTIVATION: tl.constexpr  #\n",
    "):\n",
    "    \"\"\"Kernel for computing the matmul C = A x B.\n",
    "    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n",
    "    \"\"\"\n",
    "    # -----------------------------------------------------------\n",
    "    # Map program ids `pid` to the block of C it should compute.\n",
    "    # This is done in a grouped ordering to promote L2 data reuse.\n",
    "    # See above `L2 Cache Optimizations` section for details.\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Add some integer bound assumptions.\n",
    "    # This helps to guide integer analysis in the backend to optimize\n",
    "    # load/store offset address calculation\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Create pointers for the first blocks of A and B.\n",
    "    # We will advance this pointer as we move in the K direction\n",
    "    # and accumulate\n",
    "    # `a_ptrs` is a block of [BLOCK_SIZE_M, BLOCK_SIZE_K] pointers\n",
    "    # `b_ptrs` is a block of [BLOCK_SIZE_K, BLOCK_SIZE_N] pointers\n",
    "    # See above `Pointer Arithmetic` section for details\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % M\n",
    "    offs_bn = (pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)) % N\n",
    "    offs_k = tl.arange(0, BLOCK_SIZE_K)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_k[None, :] * stride_ak)\n",
    "    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_bn[None, :] * stride_bn)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Iterate to compute a block of the C matrix.\n",
    "    # We accumulate into a `[BLOCK_SIZE_M, BLOCK_SIZE_N]` block\n",
    "    # of fp32 values for higher accuracy.\n",
    "    # `accumulator` will be converted back to fp16 after the loop.\n",
    "    accumulator_dtype = tl.float32 #tl.float16 #tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=accumulator_dtype)\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        # Load the next block of A and B, generate a mask by checking the K dimension.\n",
    "        # If it is out of bounds, set it to 0.\n",
    "        a = tl.load(a_ptrs, mask=offs_k[None, :] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        b = tl.load(b_ptrs, mask=offs_k[:, None] < K - k * BLOCK_SIZE_K, other=0.0)\n",
    "        # We accumulate along the K dimension.\n",
    "        accumulator = tl.dot(a, b, accumulator, out_dtype=accumulator_dtype)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += BLOCK_SIZE_K * stride_ak\n",
    "        b_ptrs += BLOCK_SIZE_K * stride_bk\n",
    "    # You can fuse arbitrary activation functions here\n",
    "    # while the accumulator is still in FP32!\n",
    "    if ACTIVATION == \"leaky_relu\":\n",
    "        accumulator = leaky_relu(accumulator)\n",
    "    c = accumulator.to(tl.float16)\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < M) & (offs_cn[None, :] < N)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "# We can fuse `leaky_relu` by providing it as an `ACTIVATION` meta-parameter in `matmul_kernel`.\n",
    "@triton.jit\n",
    "def leaky_relu(x):\n",
    "    return tl.where(x >= 0, x, 0.01 * x)\n",
    "\n",
    "\n",
    "# %%\n",
    "# We can now create a convenience wrapper function that only takes two input tensors,\n",
    "# and (1) checks any shape constraint; (2) allocates the output; (3) launches the above kernel.\n",
    "\n",
    "\n",
    "def matmul(a, b, activation=\"\"):\n",
    "    # Check constraints.\n",
    "    assert a.shape[1] == b.shape[0], \"Incompatible dimensions\"\n",
    "    assert a.is_contiguous(), \"Matrix A must be contiguous\"\n",
    "    M, K = a.shape\n",
    "    K, N = b.shape\n",
    "    # Allocates output.\n",
    "    c = torch.empty((M, N), device=a.device, dtype=torch.float16)\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    grid = lambda META: (triton.cdiv(M, META['BLOCK_SIZE_M']) * triton.cdiv(N, META['BLOCK_SIZE_N']), )\n",
    "    matmul_kernel[grid](\n",
    "        a, b, c,  #\n",
    "        M, N, K,  #\n",
    "        a.stride(0), a.stride(1),  #\n",
    "        b.stride(0), b.stride(1),  #\n",
    "        c.stride(0), c.stride(1),  #\n",
    "        ACTIVATION=activation  #\n",
    "    )\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2683f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def to_int4(v):\n",
    "    sign = (v & 0x8) != 0\n",
    "    mag  = (v & 0x7).to(tl.int8)\n",
    "    return tl.where(sign, -mag, mag)\n",
    "\n",
    "\n",
    "def get_cuda_autotune_config():\n",
    "    return [\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=1, num_warps=1),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=1, num_warps=2),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=1, num_warps=4),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=1, num_warps=8),\n",
    "\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=2, num_warps=1),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=2, num_warps=2),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=2, num_warps=4),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=2, num_warps=8),\n",
    "\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=3, num_warps=1),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=3, num_warps=2),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=3, num_warps=4),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=3, num_warps=8),\n",
    "\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=4, num_warps=1),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=4, num_warps=2),\n",
    "        # triton.Config({\"GROUP_SIZE_M\" : 8}, num_stages=4, num_warps=4),\n",
    "        triton.Config({\"GROUP_SIZE_M\" : 1}, num_stages=4, num_warps=8),\n",
    "        ]\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=get_cuda_autotune_config(),\n",
    "    key=[],\n",
    ")\n",
    "@triton.jit\n",
    "def matmul_trellis_kernel(\n",
    "        # Pointers to matrices\n",
    "        a_ptr, b_ptr, c_ptr,  #\n",
    "        # Matrix dimensions\n",
    "        B, IN, OUT,\n",
    "        # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "        # element in a particular dimension. E.g. `stride_am` is how much to increase `a_ptr`\n",
    "        # by to get the element one row down (A has M rows).\n",
    "        stride_am, stride_ak,  #\n",
    "        stride_bk, stride_bn,  #\n",
    "        stride_cm, stride_cn,\n",
    "        # Meta-parameters\n",
    "        BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr, BLOCK_SIZE_K: tl.constexpr,  #\n",
    "        GROUP_SIZE_M: tl.constexpr,  #\n",
    "):\n",
    "    \"\"\"Kernel for computing the matmul C = A x B.\n",
    "    A has shape (M, K), B has shape (K, N) and C has shape (M, N)\n",
    "    \"\"\"\n",
    "    # pid = tl.program_id(axis=0)\n",
    "    # grid_n = tl.cdiv(OUT, 16)\n",
    "    # pid_m = pid // grid_n\n",
    "    # pid_n = pid % grid_n\n",
    "\n",
    "\n",
    "    pid = tl.program_id(axis=0)\n",
    "    num_pid_m = tl.cdiv(B, BLOCK_SIZE_M)\n",
    "    num_pid_n = tl.cdiv(OUT, 16)\n",
    "    \n",
    "    num_pid_in_group = GROUP_SIZE_M * num_pid_n\n",
    "    group_id = pid // num_pid_in_group\n",
    "    first_pid_m = group_id * GROUP_SIZE_M\n",
    "    group_size_m = min(num_pid_m - first_pid_m, GROUP_SIZE_M)\n",
    "    pid_m = first_pid_m + ((pid % num_pid_in_group) % group_size_m)\n",
    "    pid_n = (pid % num_pid_in_group) // group_size_m\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Add some integer bound assumptions.\n",
    "    # This helps to guide integer analysis in the backend to optimize\n",
    "    # load/store offset address calculation\n",
    "    tl.assume(pid_m >= 0)\n",
    "    tl.assume(pid_n >= 0)\n",
    "    tl.assume(stride_am > 0)\n",
    "    tl.assume(stride_ak > 0)\n",
    "    tl.assume(stride_bn > 0)\n",
    "    tl.assume(stride_bk > 0)\n",
    "    tl.assume(stride_cm > 0)\n",
    "    tl.assume(stride_cn > 0)\n",
    "\n",
    "    offs_am = (pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)) % B\n",
    "    offs_ak = tl.arange(0, 16)\n",
    "    a_ptrs = a_ptr + (offs_am[:, None] * stride_am + offs_ak[None, :] * stride_ak)\n",
    "    \n",
    "    offs_low = (pid_n * 64 + tl.arange(0, 64)) % (OUT * 4)\n",
    "    offs_high = 1 + tl.arange(0, 64)\n",
    "    offs_high = (pid_n * 64 + tl.where(offs_high==64, 0, offs_high)) % (OUT * 4)\n",
    "\n",
    "    b_ptrs_low = b_ptr + offs_low\n",
    "    b_ptrs_high = b_ptr + offs_high\n",
    "        \n",
    "    accumulator_dtype = tl.float32 #tl.float16 #tl.float32\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, 16), dtype=accumulator_dtype)\n",
    "    for k in range(0, tl.cdiv(IN, 16)):\n",
    "        a = tl.load(a_ptrs, mask=offs_ak[None, :] < IN - k * 16, other=0.0)\n",
    "        bits_low = tl.load(b_ptrs_low)#, mask=offs_k[:, None] < IN - k * 16, other=0.0)\n",
    "        bits_high = tl.load(b_ptrs_high)\n",
    "        codes = bits_low.to(tl.uint16) | (bits_high.to(tl.uint16) << 8)\n",
    "        codes = ((codes.to(tl.uint32) * 34038481) >> 9).to(tl.uint16)\n",
    "\n",
    "        val0 = (codes >> 12) & 0xF\n",
    "        val1 = (codes >> 8) & 0xF\n",
    "        val2 = (codes >> 4) & 0xF\n",
    "        val3 = codes & 0xF\n",
    "\n",
    "        w0 = to_int4(val0)\n",
    "        w1 = to_int4(val1)\n",
    "        w2 = to_int4(val2)\n",
    "        w3 = to_int4(val3)\n",
    "\n",
    "        # print(\"w0\", w0)\n",
    "        # print(\"w1\", w1)\n",
    "        # print(\"w2\", w2)\n",
    "        # print(\"w3\", w3)\n",
    "\n",
    "        w01 = tl.join(w0, w2)\n",
    "        w23 = tl.join(w1, w3)\n",
    "        w = tl.join(w01, w23)\n",
    "\n",
    "        #print(w.shape)\n",
    "\n",
    "        # w01 = tl.cat(w0, w1, can_reorder=True)\n",
    "        # w23 = tl.cat(w2, w3, can_reorder=True)\n",
    "        # w = tl.cat(w01, w23, can_reorder=True)\n",
    "        \n",
    "        #w = tl.reshape(w, 4, 64)\n",
    "        #w = tl.trans(w, 1, 0)\n",
    "        #print()\n",
    "        w = tl.reshape(w, 16, 16)\n",
    "        #print(w)\n",
    "        #raise\n",
    "        # We accumulate along the K dimension.\n",
    "        # print(w)\n",
    "        accumulator = tl.dot(a, w.to(tl.float16), accumulator, out_dtype=accumulator_dtype)\n",
    "        # Advance the ptrs to the next K block.\n",
    "        a_ptrs += 16 * stride_ak\n",
    "        b_ptrs_high += 1 * stride_bk\n",
    "        b_ptrs_low += 1 * stride_bk\n",
    "\n",
    "\n",
    "    c = accumulator.to(tl.float16)\n",
    "    # -----------------------------------------------------------\n",
    "    # Write back the block of the output matrix C with masks.\n",
    "    offs_cm = pid_m * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offs_cn = pid_n * 16 + tl.arange(0, 16)\n",
    "    c_ptrs = c_ptr + stride_cm * offs_cm[:, None] + stride_cn * offs_cn[None, :]\n",
    "    c_mask = (offs_cm[:, None] < B) & (offs_cn[None, :] < OUT)\n",
    "    tl.store(c_ptrs, c, mask=c_mask)\n",
    "\n",
    "\n",
    "def trellis_matmul_triton(a, b_compressed):\n",
    "    b_compressed = b_compressed.reshape(b_compressed.shape[0], -1)\n",
    "    \n",
    "    assert a.shape[1] == b_compressed.shape[0] * 16, \"Incompatible dimensions\"\n",
    "    assert b_compressed.is_contiguous(), \"Matrix B_compressed must be contiguous\"\n",
    "\n",
    "    B, IN = a.shape\n",
    "    OUT = b_compressed.shape[-1] // 4\n",
    "\n",
    "    # Init out ptr\n",
    "    c = torch.empty((B, OUT), device=b_compressed.device, dtype=torch.float16)\n",
    "\n",
    "    # 1D launch kernel where each block gets its own program.\n",
    "    BLOCK_SIZE_M = 256\n",
    "    BLOCK_SIZE_K = 16\n",
    "    BLOCK_SIZE_N = 16\n",
    "    \n",
    "    grid = lambda META: (triton.cdiv(B, BLOCK_SIZE_M) * triton.cdiv(OUT, BLOCK_SIZE_N), )\n",
    "    matmul_trellis_kernel[grid](\n",
    "        a, b_compressed, c,  #\n",
    "        B, IN, OUT,  #\n",
    "        a.stride(0), \n",
    "        a.stride(1),  #\n",
    "        b_compressed.stride(0), \n",
    "        b_compressed.stride(1),  #\n",
    "        c.stride(0), \n",
    "        c.stride(1),  #\n",
    "        BLOCK_SIZE_M, BLOCK_SIZE_K, BLOCK_SIZE_N\n",
    "    )\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa8dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_uint16_to_int4_python(bits):\n",
    "    bits = bits.to(torch.int32)\n",
    "    val0 = (bits >> 12) & 0xF\n",
    "    val1 = (bits >> 8) & 0xF\n",
    "    val2 = (bits >> 4) & 0xF\n",
    "    val3 = bits & 0xF\n",
    "\n",
    "    sign0 = (val0 & 0x8) != 0\n",
    "    sign1 = (val1 & 0x8) != 0\n",
    "    sign2 = (val2 & 0x8) != 0\n",
    "    sign3 = (val3 & 0x8) != 0\n",
    "    \n",
    "    dtype = torch.int8\n",
    "\n",
    "    mag0 = (val0 & 0x7).to(dtype)\n",
    "    mag1 = (val1 & 0x7).to(dtype)\n",
    "    mag2 = (val2 & 0x7).to(dtype)\n",
    "    mag3 = (val3 & 0x7).to(dtype)\n",
    "    \n",
    "    w0 = torch.where(sign0, -mag0, mag0)\n",
    "    w1 = torch.where(sign1, -mag1, mag1)\n",
    "    w2 = torch.where(sign2, -mag2, mag2)\n",
    "    w3 = torch.where(sign3, -mag3, mag3)\n",
    "\n",
    "    return torch.stack([w0, w1, w2, w3], dim=-1)\n",
    "\n",
    "\n",
    "#torch.compile\n",
    "def permute_16bits(x):\n",
    "    x = x.to(torch.int32) * 34038481\n",
    "    x = (x >> 9) # & 0xFFFF\n",
    "    return x.to(torch.uint16)\n",
    "\n",
    "\n",
    "#@torch.compile()\n",
    "def decode_trellis_python(bits):\n",
    "    M, N = bits.shape[0], bits.shape[1]\n",
    "    \n",
    "    even_codes = bits.view(torch.uint16)\n",
    "    odd_codes = bits.roll(shifts=-1, dims=-1).view(torch.uint16)\n",
    "\n",
    "    codes = torch.stack([even_codes, odd_codes], dim=-1).reshape(M, N, 64)\n",
    "    \n",
    "    bits = permute_16bits(codes)\n",
    "    decoded = decode_uint16_to_int4_python(bits)\n",
    "\n",
    "    return (\n",
    "        decoded\n",
    "        .reshape(M, N, 16, 16)      # Разворачиваем в 4D: (N, M, 16, 16)\n",
    "        .permute(0, 2, 1, 3)        # Меняем оси → (N, 16, M, 16)\n",
    "        .reshape(M * 16, N * 16)    # Сшиваем в один большой 2D тензор\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def test_2x2():\n",
    "    BLOCKS = [2, 2]\n",
    "    x_compressed = torch.randint(0, 255, (BLOCKS[0], BLOCKS[1], 64), dtype=torch.uint8, device=\"cuda\")\n",
    "    x_decompressed = decode_trellis_python(x_compressed)\n",
    "    x_compressed_00 = x_compressed[0, 0][None, None, :]\n",
    "    x_decompressed_00 = decode_trellis_python(x_compressed_00)\n",
    "    assert torch.all(x_decompressed_00 == x_decompressed[:16, :16])\n",
    "\n",
    "    x_compressed_01 = x_compressed[0, 1][None, None, :]\n",
    "    x_decompressed_01 = decode_trellis_python(x_compressed_01)\n",
    "    assert torch.all(x_decompressed_01 == x_decompressed[:16, 16:32])\n",
    "\n",
    "    x_compressed_10 = x_compressed[1, 0][None, None, :]\n",
    "    x_decompressed_10 = decode_trellis_python(x_compressed_10)\n",
    "    assert torch.all(x_decompressed_10 == x_decompressed[16:32, :16])\n",
    "\n",
    "    x_compressed_11 = x_compressed[1, 1][None, None, :]\n",
    "    x_decompressed_11 = decode_trellis_python(x_compressed_11)\n",
    "    assert torch.all(x_decompressed_11 == x_decompressed[16:32, 16:32])\n",
    "    print(\"Test 2x2 passed!\")\n",
    "\n",
    "#test_2x2()\n",
    "\n",
    "#@torch.compile\n",
    "def trellis_matmul_torch(y, x_compressed):\n",
    "    x_decompressed = decode_trellis_python(x_compressed)\n",
    "    return y @ x_decompressed.to(torch.float16)\n",
    "    \n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# WEIGHT_BLOCKS = [2, 2]\n",
    "# x_compressed = torch.randint(0, 255, (WEIGHT_BLOCKS[0], WEIGHT_BLOCKS[1], 64), dtype=torch.uint8, device=\"cuda\")\n",
    "# x_decompressed = decode_trellis_python(x_compressed)\n",
    "# y = torch.randn(16 * WEIGHT_BLOCKS[1], 16  * WEIGHT_BLOCKS[0], dtype=torch.float16, device=\"cuda\")\n",
    "# y = y / (16 * math.prod(WEIGHT_BLOCKS))\n",
    "\n",
    "# o1 = trellis_matmul_torch(y, x_compressed)\n",
    "\n",
    "# # from trellis_M_16_16 import trellis_matmul_triton\n",
    "# o2 = trellis_matmul_triton(y, x_compressed)\n",
    "\n",
    "# assert torch.all(torch.isclose(o1, o2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b8959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul-performance:\n",
      "        M       N       K  torch_fp16  triton_trellis\n",
      "0   256.0   256.0   256.0    0.004036        0.013701\n",
      "1   512.0   512.0   512.0    0.005572        0.013684\n",
      "2  1024.0  1024.0  1024.0    0.005588        0.013465\n",
      "3  2048.0  1024.0  2048.0    0.005607        0.013407\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Benchmark\n",
    "# ---------\n",
    "#\n",
    "# Square Matrix Performance\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#\n",
    "# We can now compare the performance of our kernel against that of cuBLAS or rocBLAS. Here we focus on square matrices,\n",
    "# but feel free to arrange this script as you wish to benchmark any other matrix shape.\n",
    "\n",
    "configs = []\n",
    "configs.append(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=[\"M\", \"N\", \"K\"],  # Argument names to use as an x-axis for the plot\n",
    "        x_vals=[256, \n",
    "                512,\n",
    "                1024,\n",
    "                [2048, 1024, 2048], #, 1024, 1536],\n",
    "        ],\n",
    "        line_arg=\"provider\",  # Argument name whose value corresponds to a different line in the plot\n",
    "        # Possible values for `line_arg`\n",
    "        # Don't compare to cublas for fp8 cases as torch.matmul doesn't support fp8 at the moment.\n",
    "        line_vals=[\"torch_fp16\", \"triton_trellis\"],  # Label name for the lines\n",
    "        line_names=[\"torch_fp16\", \"triton_trellis\"],  # Line styles\n",
    "        #styles=[(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel=\"TFLOPS\",  # Label name for the y-axis\n",
    "        xlabel=\"Matrix size\",\n",
    "        plot_name=\"matmul-performance\",  # Name for the plot, used also as a file name for saving the plot.\n",
    "        args={},\n",
    "    ))\n",
    "\n",
    "\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, K, N, provider):\n",
    "    # a = torch.randn((M, K), device=DEVICE, dtype=torch.float16)\n",
    "    # b = torch.randn((K, N), device=DEVICE, dtype=torch.float16)\n",
    "    y = torch.randn(M, K, dtype=torch.float16, device=\"cuda\")\n",
    "    x_compressed = torch.randint(0, 255, (K // 16, N * 4, 64), dtype=torch.uint8, device=\"cuda\")\n",
    "    x_decompressed = decode_trellis_python(x_compressed).to(torch.float16)\n",
    "\n",
    "    \n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == \"torch_fp16\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(y, x_decompressed), quantiles=quantiles)\n",
    "    if provider == \"torch_trellis\":\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: trellis_matmul_torch(y, x_compressed), quantiles=quantiles)\n",
    "    if provider == 'triton_trellis':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: trellis_matmul_triton(y, x_compressed), quantiles=quantiles)\n",
    "    perf = lambda ms: 2 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)\n",
    "\n",
    "\n",
    "benchmark.run(show_plots=False, print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e1475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
